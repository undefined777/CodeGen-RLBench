#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„PPOä»£ç ç”Ÿæˆå¼ºåŒ–å­¦ä¹ è®­ç»ƒç¨‹åº

ä¸»è¦åŠŸèƒ½ï¼š
1. ä»£ç ç¿»è¯‘ä»»åŠ¡çš„PPOè®­ç»ƒ - ä¸“ä¸ºQwen2.5-Coderè®¾è®¡
2. æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€å¯¹
3. åŸºäºç¼–è¯‘æˆåŠŸç‡å’Œä»£ç ç»“æ„çš„å¥–åŠ±è®¡ç®—
4. è‡ªé€‚åº”KLæ§åˆ¶å’Œç­–ç•¥è£å‰ª
5. è¯¦ç»†çš„è®­ç»ƒç›‘æ§å’Œæ—¥å¿—è®°å½•

ä½œè€…ï¼šAI Assistant
ç‰ˆæœ¬ï¼š2.0 - Qwenä¸“ç”¨ç‰ˆæœ¬
"""

import os
import sys
import torch
import numpy as np
import datetime
import argparse
import logging
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from tqdm import tqdm
import json

# ğŸ”§ æ–°å¢ï¼šTensorboard æ”¯æŒ
from torch.utils.tensorboard import SummaryWriter

# é¡¹ç›®å†…éƒ¨å¯¼å…¥
from code_parser import (DFG_python, DFG_java, DFG_ruby, DFG_go, 
                        DFG_php, DFG_javascript, DFG_csharp)
from code_parser import (tree_to_token_index, tree_to_token_nodes,
                        index_to_code_token, tree_to_variable_index, 
                        detokenize_code)
from tree_sitter import Language, Parser
from reward import remove_special_tokens, tree_sitter_full_compile, get_reward
from torch.utils.data import DataLoader, TensorDataset
from model import respond_to_batch, QwenCoderHeadWithValueModelLocal
from transformers import AutoTokenizer
from ppo import PPOTrainer
from utils import (extract_structure, Example, InputFeatures)
from code_prepro.lang_processors import (py_tokenizer, java_tokenizer, cpp_tokenizer,
                                        c_tokenizer, js_tokenizer, php_tokenizer, cs_tokenizer,
                                        py_detokenizer, java_detokenizer, cpp_detokenizer,
                                        c_detokenizer, js_detokenizer, php_detokenizer, cs_detokenizer)
from compiler.terminal_compiler import TerminalCompiler


def extract_code_from_qwen_response(response: str, target_lang: str = "cpp") -> str:
    """
    ä»Qwenæ¨¡å‹çš„å›å¤ä¸­æå–çº¯ä»£ç 
    
    Args:
        response: Qwenæ¨¡å‹çš„å®Œæ•´å›å¤
        target_lang: ç›®æ ‡è¯­è¨€ï¼Œç”¨äºåŒ¹é…ä»£ç å—
    
    Returns:
        æå–çš„çº¯ä»£ç å­—ç¬¦ä¸²
    """
    # è¯­è¨€åç§°æ˜ å°„ï¼Œæ”¯æŒä¸åŒçš„å˜ä½“
    lang_patterns = {
        'cpp': ['cpp', 'c++', 'cxx'],
        'java': ['java'],
        'python': ['python', 'py'],
        'javascript': ['javascript', 'js'],
        'c': ['c'],
        'php': ['php'],
        'c_sharp': ['csharp', 'c#', 'cs']
    }
    
    # è·å–ç›®æ ‡è¯­è¨€çš„æ‰€æœ‰å¯èƒ½æ¨¡å¼
    target_patterns = lang_patterns.get(target_lang, [target_lang])
    
    # å°è¯•åŒ¹é…ä»£ç å—
    for pattern in target_patterns:
        # åŒ¹é… ```lang\ncode\n``` æ ¼å¼ï¼Œè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        escaped_pattern = re.escape(pattern)
        code_match = re.search(rf'```{escaped_pattern}\s*\n(.*?)\n```', response, re.DOTALL | re.IGNORECASE)
        if code_match:
            return code_match.group(1).strip()
    
    # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šè¯­è¨€çš„ä»£ç å—ï¼Œå°è¯•åŒ¹é…é€šç”¨ä»£ç å—
    code_match = re.search(r'```\s*\n(.*?)\n```', response, re.DOTALL)
    if code_match:
        return code_match.group(1).strip()
    
    # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æå–"translation:"åçš„å†…å®¹
    translation_match = re.search(r'translation:\s*\n\n(.+)', response, re.DOTALL | re.IGNORECASE)
    if translation_match:
        return translation_match.group(1).strip()
    
    # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›å»é™¤å¸¸è§å‰ç¼€åçš„å†…å®¹
    response = response.strip()
    prefixes_to_remove = [
        "Here's the C++ translation:",
        "Here's the Java translation:",
        "Here's the Python translation:",
        "Here's the translation:",
        "Translation:",
        "```",
    ]
    
    for prefix in prefixes_to_remove:
        if response.startswith(prefix):
            response = response[len(prefix):].strip()
    
    # ç§»é™¤æœ«å°¾çš„ ```
    if response.endswith("```"):
        response = response[:-3].strip()
    
    return response


def read_qwen_examples(filename: str, args) -> List[Example]:
    """
    ä»Qwenæ ¼å¼çš„JSONLæ–‡ä»¶ä¸­è¯»å–è®­ç»ƒæ ·ä¾‹
    
    Args:
        filename: JSONLæ–‡ä»¶è·¯å¾„
        args: åŒ…å«è¯­è¨€é…ç½®çš„å‚æ•°å¯¹è±¡
    
    Returns:
        Exampleå¯¹è±¡åˆ—è¡¨
    """
    examples = []
    
    with open(filename, 'r', encoding='utf-8') as f:
        for idx, line in enumerate(f):
            if not line.strip():
                continue
                
            try:
                data = json.loads(line)
                messages = data.get('messages', [])
                
                # æŸ¥æ‰¾ system / user / assistant æ¶ˆæ¯
                system_message = None
                user_message = None
                assistant_message = None
                
                for message in messages:
                    role = message.get('role')
                    if role == 'system':
                        system_message = message.get('content', '')
                    elif role == 'user':
                        user_message = message.get('content', '')
                    elif role == 'assistant':
                        assistant_message = message.get('content', '')
                
                if not user_message or not assistant_message:
                    continue
                
                # ä»useræ¶ˆæ¯ä¸­æå–æºä»£ç  - ç”¨äºæ„å»ºExample.source
                source_code = extract_code_from_qwen_response(user_message, args.source_lang)
                
                # ä»assistantæ¶ˆæ¯ä¸­æå–ç›®æ ‡ä»£ç  - ç”¨äºæ„å»ºExample.target
                target_code = extract_code_from_qwen_response(assistant_message, args.target_lang)
                
                if not source_code or not target_code:
                    continue
                
                e = Example(
                    idx=idx,
                    source=source_code,
                    target=target_code,
                    source_orig=user_message,      # å…ˆå­˜ userï¼›system å•ç‹¬æŒ‚
                    target_orig=assistant_message
                )
                # åŠ¨æ€æŒ‚è½½ systemï¼ˆè‹¥æ— åˆ™ç©ºä¸²ï¼‰
                setattr(e, "system_orig", system_message or "")
                examples.append(e)

            except (json.JSONDecodeError, KeyError, IndexError) as e:
                print(f"è·³è¿‡ç¬¬{idx+1}è¡Œï¼Œè§£æé”™è¯¯: {e}")
                continue
    
    return examples


def convert_qwen_examples_to_features(examples, tokenizer, args, stage=None):
    """
    å°†Qwenæ ·ä¾‹è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥ç‰¹å¾
    ä¸“é—¨å¤„ç†å¯¹è¯æ ¼å¼çš„tokenization
    """
    features = []
    for example_index, example in enumerate(examples):
        # å¯¹äºQwenï¼Œæˆ‘ä»¬ä½¿ç”¨å®Œæ•´çš„å¯¹è¯æ¶ˆæ¯
        # source_origåŒ…å«å®Œæ•´çš„user prompt
        # target_origåŒ…å«å®Œæ•´çš„assistantå›å¤
        
        # å¯ä»¥ä½¿ç”¨tokenizerçš„chat templateï¼Œæˆ–è€…ç®€å•æ‹¼æ¥
        if hasattr(tokenizer, 'apply_chat_template'):
            # å°è¯•ä½¿ç”¨chat template
            try:
                if hasattr(example, "system_orig") and example.system_orig:
                    # ä½¿ç”¨æ ·æœ¬è‡ªå¸¦ system
                    messages = [
                        {"role": "system", "content": example.system_orig},
                        {"role": "user", "content": example.source_orig},
                    ]
                else:
                    messages = [
                        {"role": "user", "content": example.source_orig},
                    ]
                source_text = tokenizer.apply_chat_template(
                    messages, add_generation_prompt=True, tokenize=False
                ) 
            except:
                # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                source_text = example.source_orig
        else:
            source_text = example.source_orig
            
        # tokenize source - ç›´æ¥ç¼–ç ï¼Œä¸éœ€è¦ç‰¹æ®Štoken
        source_ids = tokenizer.encode(source_text, max_length=args.max_source_length, 
                                     truncation=True, add_special_tokens=True)
        source_mask = [1] * len(source_ids)
        padding_length = args.max_source_length - len(source_ids)
        source_ids = [tokenizer.pad_token_id] * padding_length + source_ids  # âœ… left-padding
        source_mask = [0] * padding_length + source_mask  # âœ… left-padding
        
        # tokenize target
        if stage == "test":
            target_text = "None"
        else:
            target_text = example.target_orig
            
        target_ids = tokenizer.encode(target_text, max_length=args.max_target_length,
                                     truncation=True, add_special_tokens=True)
        target_mask = [1] * len(target_ids)
        padding_length = args.max_target_length - len(target_ids)
        target_ids = [tokenizer.pad_token_id] * padding_length + target_ids  # âœ… left-padding
        target_mask = [0] * padding_length + target_mask  # âœ… left-padding
        
        features.append(InputFeatures(
            example_index,
            source_ids,
            target_ids,
            source_mask,
            target_mask,
            example.target_orig))  # ä¿å­˜å®Œæ•´å›å¤ç”¨äºåç»­å¤„ç†
            
    return features


def create_reward_wrapper(original_get_reward):
    """
    Wrap the original `get_reward()` so that *each* of (policy, ref, gold)
    is decoded up to **its own** EOS, code-block extracted, re-tokenized,
    EOS-appended, and padded to a common length *before* reward computation.
    è¿™æ ·é¿å…å°† policy çš„ eos ä½ç½®è¯¯ç”¨äº ref/goldï¼ˆåŸå®ç°çš„é—®é¢˜ï¼‰ã€‚
    """
    def get_reward_with_extraction(lang, code_ids=None, code_ref_ids=None, gold_ids=None, tokenizer=None):
        # ---------- helpers ----------
        def _decode_rows(t: torch.Tensor):
            """
            Return (texts, eos_pos_list, max_seq_len) for given token ids tensor.
            """
            arr = t.detach().cpu().numpy()
            max_len = arr.shape[1]
            texts, eos_pos_list = [], []
            eos_id = tokenizer.eos_token_id
            for row in arr:
                # find EOS; if none, use max_len
                eos_pos = int((row == eos_id).argmax()) if eos_id in row else max_len
                eos_pos_list.append(eos_pos)
                texts.append(
                    tokenizer.decode(
                        row[:eos_pos],
                        skip_special_tokens=True,
                        clean_up_tokenization_spaces=False,
                    )
                )
            return texts, eos_pos_list, max_len

        # ---------- decode raw responses ----------
        raw_responses, eos_resp, max_resp = _decode_rows(code_ids)
        raw_responses_ref, eos_ref, max_ref = _decode_rows(code_ref_ids)
        raw_gold, eos_gold, max_gold = _decode_rows(gold_ids)

        # ---------- extract code blocks ----------
        extracted_codes = [extract_code_from_qwen_response(txt, lang) for txt in raw_responses]
        extracted_codes_ref = [extract_code_from_qwen_response(txt, lang) for txt in raw_responses_ref]
        extracted_codes_gold = [extract_code_from_qwen_response(txt, lang) for txt in raw_gold]

        # ---------- re-tokenize & append EOS ----------
        eos_id = tokenizer.eos_token_id
        pad_id = tokenizer.pad_token_id
        triplets = []
        for c, r, g in zip(extracted_codes, extracted_codes_ref, extracted_codes_gold):
            toks_c = tokenizer.encode(c, add_special_tokens=False) + [eos_id]
            toks_r = tokenizer.encode(r, add_special_tokens=False) + [eos_id]
            toks_g = tokenizer.encode(g, add_special_tokens=False) + [eos_id]
            triplets.append((toks_c, toks_r, toks_g))

        # ç»Ÿä¸€é•¿åº¦ï¼ˆä¸è¶…è¿‡åŸ policy è¾“å‡ºé•¿åº¦ä¸Šé™ï¼Œä»¥èŠ‚çº¦æ˜¾å­˜ï¼‰
        # ä½ ä¹Ÿå¯ä»¥ç”¨å…¨å±€ max(len)ï¼›è¿™é‡Œé‡‡ç”¨ min(global_max, policy_original_max)
        global_max = max(len(x) for tri in triplets for x in tri) if triplets else 1
        max_len = max_resp

        def _pad(seq):
            if len(seq) >= max_len:
                return seq[:max_len]
            return seq + [pad_id] * (max_len - len(seq))

        policy_padded = [_pad(x[0]) for x in triplets]
        ref_padded    = [_pad(x[1]) for x in triplets]
        gold_padded   = [_pad(x[2]) for x in triplets]

        # ---------- to tensors ----------
        code_ids_tensor     = torch.tensor(policy_padded, dtype=torch.long, device=code_ids.device)
        code_ref_ids_tensor = torch.tensor(ref_padded,    dtype=torch.long, device=code_ref_ids.device)
        gold_ids_tensor     = torch.tensor(gold_padded,   dtype=torch.long, device=gold_ids.device)

        # ---------- call original reward ----------
        return original_get_reward(
            lang=lang,
            code_ids=code_ids_tensor,
            code_ref_ids=code_ref_ids_tensor,
            gold_ids=gold_ids_tensor,
            tokenizer=tokenizer,
        )
    
    return get_reward_with_extraction


@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®æ•°æ®ç±» - Qwenä¸“ç”¨ç‰ˆæœ¬"""
    # è¯­è¨€é…ç½®
    source_lang: str
    target_lang: str
    
    # åˆ«åï¼Œç”¨äºå…¼å®¹æ—§ä»£ç 
    @property
    def l1(self):
        return self.source_lang
    
    @property
    def l2(self):
        return self.target_lang
    
    # æ¨¡å‹é…ç½®
    model_path: str
    max_source_length: int = 400
    max_target_length: int = 400
    
    # è®­ç»ƒé…ç½®
    train_batch_size: int = 16
    test_batch_size: int = 48
    train_epochs: int = 1000000
    learning_rate: float = 1e-5
    kl_coef: float = 0.05
    kl_target: float = 1.0
    vf_coef: float = 1e-3
    
    # ç”Ÿæˆé…ç½®
    action_space: int = 2  # top_k
    num_syn_samples: int = 5
    
    # è·¯å¾„é…ç½®
    data_path: str = None
    output_path: str = None
    baseline_output_path: str = None
    
    # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥ç‚¹ä¿å­˜æ§åˆ¶
    save_steps: int = 1  # æ¯Nè½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼Œé»˜è®¤æ¯è½®éƒ½ä¿å­˜
    max_checkpoints: int = 10  # æœ€å¤šä¿ç•™Nä¸ªæ£€æŸ¥ç‚¹ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
    
    # ğŸ”§ æ–°å¢ï¼šTensorboard æ”¯æŒ
    use_tensorboard: bool = True  # æ˜¯å¦å¯ç”¨Tensorboardæ—¥å¿—
    tensorboard_log_dir: str = None  # Tensorboardæ—¥å¿—ç›®å½•ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤è·¯å¾„
    log_every_n_steps: int = 1  # æ¯Nä¸ªè®­ç»ƒæ­¥éª¤è®°å½•ä¸€æ¬¡æŒ‡æ ‡
    
    # è®¾å¤‡é…ç½®
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    
    # è¿è¡Œé…ç½®
    run_id: int = 1
    seed: int = 42


class CodeTranslationTrainer:
    """ä»£ç ç¿»è¯‘PPOè®­ç»ƒå™¨ - Qwenä¸“ç”¨ç‰ˆæœ¬"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.setup_logging()
        self.setup_device()
        self.setup_language_mappings()
        self.setup_parsers()
        self.setup_models()
        self.setup_data_loaders()
        self.setup_ppo_trainer()
        self.setup_training_stats()
        
        # åˆ›å»ºå¥–åŠ±å‡½æ•°åŒ…è£…å™¨
        self.get_reward_func = create_reward_wrapper(get_reward)
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = Path(self.config.output_path) / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / f"training_{self.config.run_id}.log"),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"è®­ç»ƒé…ç½®: {self.config}")
        
    def setup_device(self):
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if self.config.device == "cuda" and not torch.cuda.is_available():
            self.logger.warning("CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
            self.config.device = "cpu"
        
        torch.manual_seed(self.config.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(self.config.seed)
            
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.config.device}")
        
    def setup_language_mappings(self):
        """è®¾ç½®è¯­è¨€æ˜ å°„"""
        self.dir_dict = {
            'javascript': 'Javascript', 'java': 'Java', 'c_sharp': 'C#', 
            'php': 'PHP', 'python': 'Python', 'c': 'C', 'cpp': 'C++'
        }
        
    def setup_parsers(self):
        """è®¾ç½®ä»£ç è§£æå™¨"""
        self.dfg_function = {
            'python': DFG_python, 'java': DFG_java, 'php': DFG_php,
            'javascript': DFG_javascript, 'c_sharp': DFG_csharp,
            'c': DFG_csharp, 'cpp': DFG_csharp,
        }
        
        self.parsers = {}
        for lang in self.dfg_function:
            try:
                LANGUAGE = Language('code_parser/my-languages.so', lang)
                parser = Parser()
                parser.set_language(LANGUAGE)
                parser = [parser, self.dfg_function[lang]]
                self.parsers[lang] = parser
            except Exception as e:
                self.logger.warning(f"æ— æ³•åŠ è½½{lang}è§£æå™¨: {e}")
                
    def setup_models(self):
        """è®¾ç½®æ¨¡å‹å’Œåˆ†è¯å™¨"""
        # è·å–æ¨¡å‹æ–‡ä»¶æ‰€åœ¨ç›®å½•
        self.model_dir = Path(self.config.model_path)
        
        # æ£€æŸ¥å¹¶å‡†å¤‡tokenizerå’Œé…ç½®æ–‡ä»¶
        self._check_model_files()
        
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°è®¾å¤‡: {self.config.device}")
        print(f"åŠ è½½æ¨¡å‹æ–‡ä»¶: {self.config.model_path}")
        
        # ç›´æ¥åŠ è½½å¾®è°ƒå¥½çš„å®Œæ•´æ¨¡å‹ï¼ˆåŒ…å«æ¶æ„ä¸æƒé‡ï¼‰â€”â€”ä¸è¦å†åˆ† config/weight ä¸¤æ­¥ã€‚:contentReference[oaicite:4]{index=4}
        self.model = QwenCoderHeadWithValueModelLocal(
            self.config.model_path,
            torch_dtype=None,              # ä¿æŒé»˜è®¤dtype; ä¸‹è¡Œç»Ÿä¸€ .to()
            device=self.config.device,
        )
        self.model.to(self.config.device)
        self.model.train() 
        
        # åŠ è½½å‚è€ƒæ¨¡å‹ï¼ˆå›ºå®šä¸å˜ï¼‰
        self.model_ref = QwenCoderHeadWithValueModelLocal(
            self.config.model_path,
            torch_dtype=None,
            device=self.config.device,
        )
        #self.model_ref.load_model_weights(self.config.model_path, self.config.device)
        self.model_ref.to(self.config.device)
        for p in self.model_ref.parameters():
            p.requires_grad = False
        self.model_ref.eval()
        
        # ä»æœ¬åœ°åŠ è½½tokenizer
        print("æ­£åœ¨ä»æœ¬åœ°åŠ è½½tokenizer...")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_dir, 
            local_files_only=True,
            trust_remote_code=True,
            padding_side='left'  # Decoder-only æ¨¡å‹ä½¿ç”¨ left-padding
)
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            print("tokenizerä»æœ¬åœ°åŠ è½½å®Œæˆï¼")
        except Exception as e:
            raise RuntimeError(f"ä»æœ¬åœ°åŠ è½½tokenizerå¤±è´¥: {e}")
        
        self.logger.info("æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½å®Œæˆ")
        
    def _check_model_files(self):
        """æ£€æŸ¥æ¨¡å‹å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
        
        # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
        if not os.path.exists(self.config.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {self.config.model_path}")
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = [
            'config.json',
            'tokenizer.json',
            'vocab.json', 
            'merges.txt',
            'special_tokens_map.json'
        ]
        
        missing_files = []
        for file_name in required_files:
            file_path = self.model_dir / file_name
            if not file_path.exists():
                missing_files.append(file_name)
        
        if missing_files:
            raise FileNotFoundError(
                f"ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶: {missing_files}\n"
                f"è¯·ç¡®ä¿æ¨¡å‹ç›®å½• {self.model_dir} åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶:\n"
                f"  - config.json (æ¨¡å‹é…ç½®)\n"
                f"  - tokenizer.json (åˆ†è¯å™¨é…ç½®)\n"
                f"  - vocab.json (è¯æ±‡è¡¨)\n"
                f"  - merges.txt (BPEåˆå¹¶è§„åˆ™)\n"
                f"  - special_tokens_map.json (ç‰¹æ®Štokenæ˜ å°„)\n"
                f"  - {Path(self.config.model_path).name} (æ¨¡å‹æƒé‡)"
            )
        
        print("âœ“ æ‰€æœ‰å¿…è¦æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        
    def setup_data_loaders(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        # æ„å»ºæ•°æ®æ–‡ä»¶è·¯å¾„
        self.data_files = self._build_data_paths()
        
        # åŠ è½½æ•°æ®
        self.train_examples = read_qwen_examples(self.data_files['train'], self.config)
        self.dev_examples = read_qwen_examples(self.data_files['dev'], self.config)
        self.test_examples = read_qwen_examples(self.data_files['test'], self.config)
        
        # è½¬æ¢ä¸ºç‰¹å¾
        self.train_features = convert_qwen_examples_to_features(
            self.train_examples, self.tokenizer, self.config, stage='train'
        )
        self.dev_features = convert_qwen_examples_to_features(
            self.dev_examples, self.tokenizer, self.config, stage='train'
        )
        self.test_features = convert_qwen_examples_to_features(
            self.test_examples, self.tokenizer, self.config, stage='train'
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_dataloader = self._create_dataloader(
            self.train_features, self.config.train_batch_size, shuffle=True
        )
        self.dev_dataloader = self._create_dataloader(
            self.dev_features, self.config.train_batch_size, shuffle=False
        )
        self.test_dataloader = self._create_dataloader(
            self.test_features, self.config.test_batch_size, shuffle=False
        )
        
        self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆ - è®­ç»ƒ: {len(self.train_features)}, "
                        f"éªŒè¯: {len(self.dev_features)}, æµ‹è¯•: {len(self.test_features)}")
        
    def _build_data_paths(self) -> Dict[str, str]:
        """æ„å»ºQwenæ ¼å¼æ•°æ®æ–‡ä»¶è·¯å¾„"""
        l1, l2 = self.config.source_lang, self.config.target_lang
        
        # å°è¯•ä¸åŒçš„è·¯å¾„ç»„åˆ
        possible_paths = [
            f"{self.config.data_path}/qwen/{self.dir_dict[l1]}-{self.dir_dict[l2]}/",
            f"{self.config.data_path}/qwen/{self.dir_dict[l2]}-{self.dir_dict[l1]}/",
            f"{self.config.data_path}/{self.dir_dict[l1]}-{self.dir_dict[l2]}/",  # å¤‡é€‰è·¯å¾„
            f"{self.config.data_path}/{self.dir_dict[l2]}-{self.dir_dict[l1]}/"   # å¤‡é€‰è·¯å¾„
        ]
        
        data_dir = None
        for path in possible_paths:
            if os.path.exists(path):
                data_dir = path
                break
                
        if data_dir is None:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°Qwenæ ¼å¼æ•°æ®ç›®å½•: {possible_paths}")
            
        return {
            'train': f"{data_dir}train.jsonl",
            'dev': f"{data_dir}val.jsonl",
            'test': f"{data_dir}test.jsonl"
        }
        
    def _create_dataloader(self, features: List[InputFeatures], 
                          batch_size: int, shuffle: bool = False) -> DataLoader:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        all_source_ids = torch.tensor([f.source_ids for f in features], dtype=torch.long)
        all_source_mask = torch.tensor([f.source_mask for f in features], dtype=torch.long)
        all_target_ids = torch.tensor([f.target_ids for f in features], dtype=torch.long)
        all_target_mask = torch.tensor([f.target_mask for f in features], dtype=torch.long)
        indices = torch.arange(len(features))
        
        dataset = TensorDataset(all_source_ids, all_source_mask, 
                               all_target_ids, all_target_mask, indices)
        
        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)
        
    def setup_ppo_trainer(self):
        """è®¾ç½®PPOè®­ç»ƒå™¨"""
        ppo_config = {
            "batch_size": self.config.train_batch_size,
            'eos_token_id': self.tokenizer.eos_token_id,
            'lr': self.config.learning_rate,
            "adap_kl_ctrl": True,
            'init_kl_coef': self.config.kl_coef,
            "target": self.config.kl_target,
            "vf_coef": self.config.vf_coef
        }
        
        self.ppo_trainer = PPOTrainer(self.model, self.model_ref, **ppo_config)
        self.logger.info("PPOè®­ç»ƒå™¨è®¾ç½®å®Œæˆ")
        
    def setup_training_stats(self):
        """è®¾ç½®è®­ç»ƒç»Ÿè®¡"""
        self.training_stats = {
            'nsteps': 0,
            'total_nerrors': 0,
            'total_rewards': 0,
            'total_nnodes': 0,
            'total_nerrors_ref': 0,
            'total_nnodes_ref': 0,
            'total_seen': 0
        }
        
        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir = Path(self.config.output_path) / "results"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
        self.checkpoint_dir = Path(self.config.output_path) / "checkpoints"
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ”§ æ–°å¢ï¼šåˆå§‹åŒ– Tensorboard
        self.tensorboard_writer = None
        if self.config.use_tensorboard:
            # è®¾ç½®Tensorboardæ—¥å¿—ç›®å½•
            if self.config.tensorboard_log_dir:
                tb_log_dir = Path(self.config.tensorboard_log_dir)
            else:
                tb_log_dir = Path(self.config.output_path) / "tensorboard"
            
            # æ·»åŠ æ—¶é—´æˆ³å’Œè¿è¡ŒIDåˆ°æ—¥å¿—ç›®å½•
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            tb_log_dir = tb_log_dir / f"run_{self.config.run_id}_{timestamp}"
            tb_log_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆå§‹åŒ–SummaryWriter
            self.tensorboard_writer = SummaryWriter(log_dir=str(tb_log_dir))
            self.logger.info(f"Tensorboardæ—¥å¿—ä¿å­˜åˆ°: {tb_log_dir}")
            
            # è®°å½•é…ç½®ä¿¡æ¯
            config_text = str(self.config).replace(',', '\n')
            self.tensorboard_writer.add_text("Config", config_text, 0)
        else:
            self.logger.info("Tensorboardæ—¥å¿—å·²ç¦ç”¨")
            
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        self.logger.info("å¼€å§‹è®­ç»ƒ...")
        
        for epoch in range(self.config.train_epochs):
            self.logger.info(f"å¼€å§‹ç¬¬ {epoch} è½®è®­ç»ƒ")
            
            # æ¯è½®è¿›è¡Œå¤šæ¬¡é‡‡æ ·
            for sample_idx in range(self.config.num_syn_samples):
                self._train_epoch(epoch, sample_idx)
                
            # ä¿å­˜æ¨¡å‹å’Œè¯„ä¼°
            self._save_checkpoint(epoch)
            self._evaluate(epoch)
            
    def _train_epoch(self, epoch: int, sample_idx: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        pbar = tqdm(self.train_dataloader, desc=f"Epoch {epoch}, Sample {sample_idx}")
        
        for batch_idx, batch in enumerate(pbar):
            # å¤„ç†æ‰¹æ¬¡æ•°æ®
            batch = tuple(t.to(self.config.device) for t in batch)
            # DataLoader è¿”å› (source_ids, source_mask, target_ids, target_mask, indices)
            source_ids, source_mask, target_ids, target_mask, ind = batch
            # ç”Ÿæˆä»£ç 
            response_ids = self._generate_code(source_ids, source_mask)
            response_ids_ref = self._generate_code_ref(source_ids, source_mask)

            # è®¡ç®—å¥–åŠ±
            reward, metrics = self._compute_reward(response_ids, response_ids_ref, target_ids)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_stats(reward, metrics, len(source_ids))
            
            # PPOè®­ç»ƒæ­¥éª¤
            train_stats = self.ppo_trainer.step(
                source_ids, source_mask, response_ids, response_ids_ref, 
                reward.to(self.config.device)
            )
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_description(
                f"Epoch {epoch}, Sample {sample_idx}, "
                f"Avg Errors: {self.training_stats['total_nerrors']/self.training_stats['total_seen']:.5f}"
            )
            
            # è®°å½•è®­ç»ƒç»Ÿè®¡
            self._log_training_step(epoch, sample_idx, batch_idx, reward, metrics, train_stats)
            
            self.training_stats['nsteps'] += 1
            
    def _generate_code(self, source_ids: torch.Tensor, source_mask: torch.Tensor) -> torch.Tensor:
        """ç”Ÿæˆä»£ç """
        full = respond_to_batch(
            self.model, source_ids, source_mask,
            max_target_length=self.config.max_target_length,
            top_k=self.config.action_space, top_p=1.0,
            tokenizer=self.tokenizer
        ).detach()
        # fullåŒ…å« [prompt | generated]ï¼›ä»…ä¿ç•™generatedéƒ¨åˆ†
        gen_start = source_ids.size(1)
        return torch.clone(full[:, gen_start:])  # [B, <=max_new_tokens]
        
    def _generate_code_ref(self, source_ids: torch.Tensor, source_mask: torch.Tensor) -> torch.Tensor:
        """ç”Ÿæˆå‚è€ƒä»£ç """
        full = respond_to_batch(
            self.model_ref, source_ids, source_mask,
            max_target_length=self.config.max_target_length,
            top_k=self.config.action_space, top_p=1.0,
            tokenizer=self.tokenizer
        ).detach()
        # fullåŒ…å« [prompt | generated]ï¼›ä»…ä¿ç•™generatedéƒ¨åˆ†
        gen_start = source_ids.size(1)
        return torch.clone(full[:, gen_start:])  # [B, <=max_new_tokens]
        
    def _compute_reward(self, response_ids: torch.Tensor, response_ids_ref: torch.Tensor, 
                       target_ids: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """è®¡ç®—å¥–åŠ±"""
        reward, mean_rate, mean_ast_match, mean_dfg_match, num_errors, num_errors_ref, num_nodes, num_nodes_ref = self.get_reward_func(
            lang=self.config.target_lang,
            code_ids=response_ids,
            code_ref_ids=response_ids_ref,
            gold_ids=target_ids,
            tokenizer=self.tokenizer
        )
        
        metrics = {
            'mean_rate': mean_rate,
            'mean_ast_match': mean_ast_match,
            'mean_dfg_match': mean_dfg_match,
            'num_errors': num_errors,
            'num_errors_ref': num_errors_ref,
            'num_nodes': num_nodes,
            'num_nodes_ref': num_nodes_ref
        }
        
        return reward, metrics
        
    def _update_stats(self, reward: torch.Tensor, metrics: Dict, batch_size: int):
        """æ›´æ–°è®­ç»ƒç»Ÿè®¡"""
        self.training_stats['total_rewards'] += float(sum(reward.sum(axis=-1).tolist()))
        self.training_stats['total_nerrors'] += sum(metrics['num_errors'])
        self.training_stats['total_nnodes'] += sum(metrics['num_nodes'])
        self.training_stats['total_nerrors_ref'] += sum(metrics['num_errors_ref'])
        self.training_stats['total_nnodes_ref'] += sum(metrics['num_nodes_ref'])
        self.training_stats['total_seen'] += batch_size
        
    def _log_training_step(self, epoch: int, sample_idx: int, batch_idx: int,
                          reward: torch.Tensor, metrics: Dict, train_stats: Dict):
        """è®°å½•è®­ç»ƒæ­¥éª¤"""
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_reward = float(sum(reward.sum(axis=-1).tolist())) / len(reward)
        avg_errors = sum(metrics['num_errors']) / len(metrics['num_errors'])
        avg_errors_ref = sum(metrics['num_errors_ref']) / len(metrics['num_errors_ref'])
        avg_nodes = sum(metrics['num_nodes']) / len(metrics['num_nodes'])
        avg_nodes_ref = sum(metrics['num_nodes_ref']) / len(metrics['num_nodes_ref'])
        
        # ğŸ”§ æ–°å¢ï¼šè®°å½•åˆ° Tensorboard
        if (self.tensorboard_writer and 
            self.training_stats['nsteps'] % self.config.log_every_n_steps == 0):
            
            global_step = self.training_stats['nsteps']
            
            # å¥–åŠ±ç›¸å…³æŒ‡æ ‡
            self.tensorboard_writer.add_scalar("Training/Average_Reward", avg_reward, global_step)
            self.tensorboard_writer.add_scalar("Training/Compilation_Success_Rate", metrics['mean_rate'], global_step)
            self.tensorboard_writer.add_scalar("Training/AST_Match_Score", metrics['mean_ast_match'], global_step)
            self.tensorboard_writer.add_scalar("Training/DFG_Match_Score", metrics['mean_dfg_match'], global_step)
            
            # ä»£ç è´¨é‡æŒ‡æ ‡
            self.tensorboard_writer.add_scalar("Code_Quality/Avg_Errors", avg_errors, global_step)
            self.tensorboard_writer.add_scalar("Code_Quality/Avg_Errors_Ref", avg_errors_ref, global_step)
            self.tensorboard_writer.add_scalar("Code_Quality/Avg_Nodes", avg_nodes, global_step)
            self.tensorboard_writer.add_scalar("Code_Quality/Avg_Nodes_Ref", avg_nodes_ref, global_step)
            
            # PPOè®­ç»ƒæŒ‡æ ‡
            if 'objective/kl' in train_stats:
                self.tensorboard_writer.add_scalar(
                    "PPO/KL_Divergence", float(train_stats['objective/kl']), global_step
                )
            if 'objective/entropy' in train_stats:
                self.tensorboard_writer.add_scalar(
                    "PPO/Entropy", float(train_stats['objective/entropy']), global_step
                )
            if 'ppo/loss/total' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Total_Loss", train_stats['ppo/loss/total'].item(), global_step)
            if 'ppo/loss/policy' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Policy_Loss", train_stats['ppo/loss/policy'].item(), global_step)
            if 'ppo/loss/value' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Value_Loss", train_stats['ppo/loss/value'].item(), global_step)
            if 'ppo/policy/advantages_mean' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Advantages_Mean", train_stats['ppo/policy/advantages_mean'].item(), global_step)
            if 'ppo/returns/mean' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Returns_Mean", train_stats['ppo/returns/mean'].item(), global_step)
            if 'ppo/val/mean' in train_stats:
                self.tensorboard_writer.add_scalar("PPO/Value_Mean", train_stats['ppo/val/mean'].item(), global_step)
            
            # å­¦ä¹ ç‡ï¼ˆå¦‚æœå¯è·å–ï¼‰
            try:
                current_lr = self.ppo_trainer.optimizer.param_groups[0]['lr']
                self.tensorboard_writer.add_scalar("Training/Learning_Rate", current_lr, global_step)
            except:
                pass
        
        # è®°å½•åˆ°CSVæ–‡ä»¶
        csv_line = [
            datetime.datetime.now().strftime("%H:%M:%S"),
            str(self.config.run_id),
            str(self.config.train_batch_size),
            str(self.config.max_source_length),
            str(self.config.max_target_length),
            str(self.config.learning_rate),
            str(epoch),
            str(self.training_stats['nsteps']),
            f"{avg_reward:.4f}",
            f"{avg_errors:.4f}",
            f"{avg_errors_ref:.4f}",
            f"{avg_nodes:.4f}",
            f"{avg_nodes_ref:.4f}",
            str(float(train_stats['objective/kl'])),
            str(float(train_stats['objective/entropy'])),
            str(train_stats['ppo/loss/total'].item()),
            str(train_stats['ppo/loss/policy'].item()),
            str(train_stats['ppo/loss/value'].item()),
            str(train_stats['ppo/policy/advantages_mean'].item()),
            str(train_stats['ppo/returns/mean'].item()),
            str(train_stats['ppo/val/mean'].item()),
            str(metrics['mean_rate']),
            str(metrics['mean_ast_match']),
            str(metrics['mean_dfg_match'])
        ]
        
        csv_file = self.results_dir / f"{self.config.source_lang}-{self.config.target_lang}.csv"
        with open(csv_file, 'a') as f:
            f.write(','.join(csv_line) + '\n')
            
    def _save_checkpoint(self, epoch: int):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model
        checkpoint_path = self.checkpoint_dir / f"pytorch_model_ep{epoch}.bin"
        torch.save(model_to_save.state_dict(), checkpoint_path)
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {checkpoint_path}")
        
        # ğŸ”§ æ–°å¢ï¼šæ¸…ç†æ—§æ£€æŸ¥ç‚¹
        self._cleanup_old_checkpoints()
        
    def _cleanup_old_checkpoints(self):
        """æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œåªä¿ç•™æœ€æ–°çš„Nä¸ª"""
        if self.config.max_checkpoints <= 0:
            return  # ä¸é™åˆ¶æ£€æŸ¥ç‚¹æ•°é‡
            
        # è·å–æ‰€æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶
        checkpoint_pattern = "pytorch_model_ep*.bin"
        checkpoint_files = list(self.checkpoint_dir.glob(checkpoint_pattern))
        
        if len(checkpoint_files) <= self.config.max_checkpoints:
            return  # æ•°é‡æœªè¶…é™
            
        # æŒ‰ç…§ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        checkpoint_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # åˆ é™¤è¶…å‡ºé™åˆ¶çš„æ—§æ–‡ä»¶
        files_to_delete = checkpoint_files[self.config.max_checkpoints:]
        
        for file_path in files_to_delete:
            try:
                file_path.unlink()
                self.logger.info(f"åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {file_path}")
            except Exception as e:
                self.logger.warning(f"åˆ é™¤æ£€æŸ¥ç‚¹å¤±è´¥ {file_path}: {e}")
                
        if files_to_delete:
            self.logger.info(f"å·²æ¸…ç† {len(files_to_delete)} ä¸ªæ—§æ£€æŸ¥ç‚¹ï¼Œä¿ç•™æœ€æ–°çš„ {self.config.max_checkpoints} ä¸ª")
                
    def _evaluate(self, epoch: int):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        self.logger.info(f"å¼€å§‹ç¬¬ {epoch} è½®è¯„ä¼°")
        
        # è®­ç»ƒé›†è¯„ä¼°
        train_errors, train_errors_ref = self._evaluate_dataset(
            epoch, self.train_features, self.train_dataloader, 'train'
        )
        self.model.train()
        
            # æµ‹è¯•é›†è¯„ä¼°
        test_errors, test_errors_ref = self._evaluate_dataset(
            epoch, self.test_features, self.test_dataloader, 'test'
        )
        self.model.train()
        
        self.logger.info(f"Epoch {epoch} è¯„ä¼°ç»“æœ:")
        self.logger.info(f"  è®­ç»ƒé›† - æ¨¡å‹é”™è¯¯: {train_errors}, å‚è€ƒæ¨¡å‹é”™è¯¯: {train_errors_ref}")
        self.logger.info(f"  æµ‹è¯•é›† - æ¨¡å‹é”™è¯¯: {test_errors}, å‚è€ƒæ¨¡å‹é”™è¯¯: {test_errors_ref}")
        
        # ğŸ”§ æ–°å¢ï¼šè®°å½•è¯„ä¼°æŒ‡æ ‡åˆ° Tensorboard
        if self.tensorboard_writer:
            self.tensorboard_writer.add_scalar("Evaluation/Train_Errors", train_errors, epoch)
            self.tensorboard_writer.add_scalar("Evaluation/Train_Errors_Ref", train_errors_ref, epoch)
            self.tensorboard_writer.add_scalar("Evaluation/Test_Errors", test_errors, epoch)
            self.tensorboard_writer.add_scalar("Evaluation/Test_Errors_Ref", test_errors_ref, epoch)
            
            # è®¡ç®—é”™è¯¯ç‡
            if len(self.train_features) > 0:
                train_error_rate = train_errors / len(self.train_features)
                self.tensorboard_writer.add_scalar("Evaluation/Train_Error_Rate", train_error_rate, epoch)
            
            if len(self.test_features) > 0:
                test_error_rate = test_errors / len(self.test_features)
                self.tensorboard_writer.add_scalar("Evaluation/Test_Error_Rate", test_error_rate, epoch)
        self.model.train()
            
    def _evaluate_dataset(self, epoch: int, features: List[InputFeatures], 
                         dataloader: DataLoader, prefix: str) -> Tuple[int, int]:
        """è¯„ä¼°æ•°æ®é›†"""
        pred_ids = []
        pred_ids_ref = []
        indices = []
        nerrors = 0
        nerrors_ref = 0
        
        with torch.no_grad():
            for batch in dataloader:
                batch = tuple(t.to(self.config.device) for t in batch)
                source_ids, source_mask, target_ids, target_mask, ind = batch
                
                # ç”Ÿæˆé¢„æµ‹
                full_preds = respond_to_batch(
                    self.model, source_ids, source_mask,
                    max_target_length=self.config.max_target_length,
                    top_k=self.config.action_space, top_p=1.0,
                    tokenizer=self.tokenizer
                )
                preds = full_preds[:, source_ids.size(1):]
                
                full_preds_ref = respond_to_batch(
                    self.model_ref, source_ids, source_mask,
                    max_target_length=self.config.max_target_length,
                    top_k=self.config.action_space, top_p=1.0,
                    tokenizer=self.tokenizer
                )
                preds_ref = full_preds_ref[:, source_ids.size(1):]
                
                # è®¡ç®—é”™è¯¯æ•°
                nerrors += sum(self.get_reward_func(
                    lang=self.config.target_lang,
                    code_ids=preds,
                    code_ref_ids=preds_ref,
                    gold_ids=target_ids,
                    tokenizer=self.tokenizer
                )[4])
                
                nerrors_ref += sum(self.get_reward_func(
                    lang=self.config.target_lang,
                    code_ids=preds_ref,
                    code_ref_ids=preds_ref,
                    gold_ids=target_ids,
                    tokenizer=self.tokenizer
                )[5])
                
                # ä¿å­˜é¢„æµ‹ç»“æœ
                pred_ids.extend(list(preds.cpu().numpy()))
                pred_ids_ref.extend(list(preds_ref.cpu().numpy()))
                indices.extend(list(ind.cpu().numpy()))
                
        # è§£ç å¹¶ä¿å­˜ç»“æœ
        self._save_predictions(epoch, prefix, pred_ids, pred_ids_ref, indices, features)
        
        return nerrors, nerrors_ref
        
    def _save_predictions(self, epoch: int, prefix: str, pred_ids: List, 
                         pred_ids_ref: List, indices: List, features: List[InputFeatures]):
        """ä¿å­˜é¢„æµ‹ç»“æœ"""
        # è§£ç é¢„æµ‹ç»“æœ
        raw_predictions = [
            self.tokenizer.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=False)
            for id in pred_ids
        ]
        raw_predictions_ref = [
            self.tokenizer.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=False)
            for id in pred_ids_ref
        ]
        
        # ä»Qwenå“åº”ä¸­æå–ä»£ç 
        predictions = [
            extract_code_from_qwen_response(pred, self.config.target_lang)
            for pred in raw_predictions
        ]
        predictions_ref = [
            extract_code_from_qwen_response(pred, self.config.target_lang)
            for pred in raw_predictions_ref
        ]
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        model_file = self.checkpoint_dir / f"{prefix}.model_ep{epoch}"
        ref_file = self.checkpoint_dir / f"{prefix}.model_ref_ep{epoch}"
        gold_file = self.checkpoint_dir / f"{prefix}.gold_ep{epoch}"
        
        with open(model_file, 'w') as f_model, \
             open(ref_file, 'w') as f_ref, \
             open(gold_file, 'w') as f_gold:
            
            for pred, ref, i in zip(predictions, predictions_ref, indices):
                f_model.write(pred + '\n')
                f_ref.write(ref + '\n')
                # å¯¹äºgoldï¼Œä¹Ÿéœ€è¦æå–ä»£ç 
                gold_code = extract_code_from_qwen_response(features[i].target, self.config.target_lang)
                f_gold.write(gold_code + '\n')


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Qwen2.5-Coder PPOä»£ç ç”Ÿæˆè®­ç»ƒç¨‹åº")
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--source_lang", required=True, type=str,
                       help="æºä»£ç è¯­è¨€")
    parser.add_argument("--target_lang", required=True, type=str,
                       help="ç›®æ ‡ä»£ç è¯­è¨€")
    parser.add_argument("--model_path", required=True, type=str,
                       help="Qwen2.5-Coderæ¨¡å‹è·¯å¾„")
    parser.add_argument("--data_path", required=True, type=str,
                       help="Qwenæ ¼å¼æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--output_path", required=True, type=str,
                       help="è¾“å‡ºç›®å½•è·¯å¾„")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--max_source_length", default=400, type=int,
                       help="æœ€å¤§æºä»£ç é•¿åº¦")
    parser.add_argument("--max_target_length", default=400, type=int,
                       help="æœ€å¤§ç›®æ ‡ä»£ç é•¿åº¦")
    parser.add_argument("--train_batch_size", default=16, type=int,
                       help="è®­ç»ƒæ‰¹æ¬¡å¤§å°")
    parser.add_argument("--test_batch_size", default=48, type=int,
                       help="æµ‹è¯•æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--train_epochs", default=1000000, type=int,
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--learning_rate", type=float, default=1e-5,
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--kl_coef", type=float, default=0.05,
                       help="KLç³»æ•°")
    parser.add_argument("--kl_target", type=float, default=1.0,
                       help="KLç›®æ ‡å€¼")
    parser.add_argument("--vf_coef", type=float, default=1e-3,
                       help="ä»·å€¼å‡½æ•°ç³»æ•°")
    parser.add_argument("--action_space", default=2, type=int,
                       help="åŠ¨ä½œç©ºé—´å¤§å°ï¼ˆtop_kï¼‰")
    parser.add_argument("--num_syn_samples", default=5, type=int,
                       help="æ¯è½®é‡‡æ ·æ¬¡æ•°")
    parser.add_argument("--run_id", default=1, type=int,
                       help="è¿è¡ŒID")
    parser.add_argument("--seed", default=42, type=int,
                       help="éšæœºç§å­")
    
    # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥ç‚¹ä¿å­˜æ§åˆ¶å‚æ•°
    parser.add_argument("--save_steps", default=1, type=int,
                       help="æ¯Nè½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼ˆé»˜è®¤æ¯è½®éƒ½ä¿å­˜ï¼‰")
    parser.add_argument("--max_checkpoints", default=10, type=int,
                       help="æœ€å¤šä¿ç•™Nä¸ªæ£€æŸ¥ç‚¹ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶ï¼ˆé»˜è®¤ä¿ç•™10ä¸ªï¼‰")
    
    # ğŸ”§ æ–°å¢ï¼šTensorboard æ”¯æŒå‚æ•°
    parser.add_argument("--use_tensorboard", action="store_true", default=True,
                       help="å¯ç”¨Tensorboardæ—¥å¿—è®°å½•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--no_tensorboard", action="store_false", dest="use_tensorboard",
                       help="ç¦ç”¨Tensorboardæ—¥å¿—è®°å½•")
    parser.add_argument("--tensorboard_log_dir", default=None, type=str,
                       help="Tensorboardæ—¥å¿—ç›®å½•ï¼ˆé»˜è®¤ä¸ºoutput_path/tensorboardï¼‰")
    parser.add_argument("--log_every_n_steps", default=1, type=int,
                       help="æ¯Nä¸ªè®­ç»ƒæ­¥éª¤è®°å½•ä¸€æ¬¡æŒ‡æ ‡åˆ°Tensorboardï¼ˆé»˜è®¤æ¯æ­¥éƒ½è®°å½•ï¼‰")
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # åˆ›å»ºé…ç½®å¯¹è±¡
    config = TrainingConfig(
        source_lang=args.source_lang,
        target_lang=args.target_lang,
        model_path=args.model_path,
        data_path=args.data_path,
        output_path=args.output_path,
        max_source_length=args.max_source_length,
        max_target_length=args.max_target_length,
        train_batch_size=args.train_batch_size,
        test_batch_size=args.test_batch_size,
        train_epochs=args.train_epochs,
        learning_rate=args.learning_rate,
        kl_coef=args.kl_coef,
        kl_target=args.kl_target,
        vf_coef=args.vf_coef,
        action_space=args.action_space,
        num_syn_samples=args.num_syn_samples,
        run_id=args.run_id,
        seed=args.seed,
        save_steps=args.save_steps,
        max_checkpoints=args.max_checkpoints,
        use_tensorboard=args.use_tensorboard,
        tensorboard_log_dir=args.tensorboard_log_dir,
        log_every_n_steps=args.log_every_n_steps
    )
    
    print("=" * 60)
    print("ğŸš€ Qwen2.5-Coder PPOä»£ç ç¿»è¯‘è®­ç»ƒç¨‹åº")
    print("=" * 60)
    print(f"ğŸ“ æºè¯­è¨€: {config.source_lang}")
    print(f"ğŸ¯ ç›®æ ‡è¯­è¨€: {config.target_lang}")
    print(f"ğŸ¤– æ¨¡å‹è·¯å¾„: {config.model_path}")
    print(f"ğŸ“‚ æ•°æ®è·¯å¾„: {config.data_path}")
    print(f"ğŸ’¾ è¾“å‡ºè·¯å¾„: {config.output_path}")
    print(f"ğŸ”§ è®¾å¤‡: {config.device}")
    print("=" * 60)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = CodeTranslationTrainer(config)
    trainer.train()


if __name__ == "__main__":
    main() 