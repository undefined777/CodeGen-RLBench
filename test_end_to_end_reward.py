#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯• - ä½¿ç”¨çœŸå®å¾®è°ƒçš„Qwenæ¨¡å‹

å®Œæ•´æµç¨‹æµ‹è¯•ï¼š
æŠ½æ ·æœ¬ -> tokenize -> è¾“å…¥æ¨¡å‹ -> å¾—åˆ°è¾“å‡º -> decode -> æå–ä»£ç  -> è®¡ç®—reward

ä½¿ç”¨ç”¨æˆ·å¾®è°ƒçš„Qwenæ¨¡å‹è¿›è¡ŒçœŸå®æµ‹è¯•
"""

import os
import sys
import json
import torch
import random
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Any
import time
from transformers import AutoTokenizer, AutoModelForCausalLM

# å¯¼å…¥æµ‹è¯•ç›¸å…³æ¨¡å—
from optimized_rl_trainer import (
    extract_code_from_qwen_response,
    create_reward_wrapper,
)
from reward import get_reward


def load_qwen_model_and_tokenizer(model_path: str):
    """åŠ è½½å¾®è°ƒè¿‡çš„Qwenæ¨¡å‹å’Œtokenizer"""
    print(f"ğŸ”§ åŠ è½½Qwenæ¨¡å‹å’Œtokenizer...")
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}")
    
    model_path = Path(model_path).expanduser()
    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    print("ğŸ“¥ åŠ è½½tokenizer...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True,
            padding_side='left'
        )
        
        # ç¡®ä¿æœ‰pad token
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            
        print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")
        print(f"   è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
        print(f"   PAD token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})")
        print(f"   EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})")
        
    except Exception as e:
        print(f"âŒ TokenizeråŠ è½½å¤±è´¥: {e}")
        raise
    
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   è®¾å¤‡: {next(model.parameters()).device}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
    
    return tokenizer, model


def load_test_samples(data_file: Path, num_samples: int = 5) -> List[Dict]:
    """ä»æ•°æ®é›†ä¸­åŠ è½½æµ‹è¯•æ ·æœ¬"""
    print(f"ğŸ“‚ ä» {data_file} åŠ è½½ {num_samples} ä¸ªæµ‹è¯•æ ·æœ¬...")
    
    if not data_file.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
    
    samples = []
    with open(data_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if len(samples) >= num_samples:
                break
            
            try:
                data = json.loads(line.strip())
                messages = data['messages']
                
                # éªŒè¯æ•°æ®æ ¼å¼
                has_user = any(msg['role'] == 'user' for msg in messages)
                has_assistant = any(msg['role'] == 'assistant' for msg in messages)
                
                if has_user and has_assistant:
                    samples.append(data)
                    print(f"âœ… æ ·æœ¬ {len(samples)}: åŠ è½½æˆåŠŸ")
                else:
                    print(f"âš ï¸  æ ·æœ¬ {i+1}: æ ¼å¼ä¸å®Œæ•´ï¼Œè·³è¿‡")
                    
            except Exception as e:
                print(f"âš ï¸  æ ·æœ¬ {i+1}: è§£æå¤±è´¥ - {e}")
    
    print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    return samples


def construct_model_input(sample: Dict, tokenizer) -> Tuple[str, str, str]:
    """æ„é€ æ¨¡å‹è¾“å…¥å¹¶æå–å‚è€ƒç­”æ¡ˆ"""
    messages = sample['messages']
    
    # æå–ç”¨æˆ·è¾“å…¥ï¼ˆJavaä»£ç ç¿»è¯‘ä»»åŠ¡ï¼‰
    user_content = None
    assistant_content = None
    
    for msg in messages:
        if msg['role'] == 'user':
            user_content = msg['content']
        elif msg['role'] == 'assistant':
            assistant_content = msg['content']
    
    # æ„é€ å¯¹è¯æ ¼å¼çš„è¾“å…¥
    system_prompt = "You are a helpful assistant for code translation. You specialize in translating Java code to C++ code while maintaining functionality and best practices."
    
    # æ„é€ è¾“å…¥æ¶ˆæ¯
    input_messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content}
    ]
    
    # ä½¿ç”¨tokenizerçš„chat template
    input_text = tokenizer.apply_chat_template(
        input_messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    return input_text, user_content, assistant_content


def generate_model_response(model, tokenizer, input_text: str, max_new_tokens: int = 512) -> str:
    """ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå“åº”"""
    print("ğŸ¤– æ¨¡å‹ç”Ÿæˆå“åº”...")
    
    # Tokenizeè¾“å…¥
    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=2048
    )
    
    # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
    device = next(model.parameters()).device
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    print(f"ğŸ“Š è¾“å…¥é•¿åº¦: {inputs['input_ids'].shape[1]} tokens")
    
    # ç”Ÿæˆå“åº”
    with torch.no_grad():
        start_time = time.time()
        
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
        
        generation_time = time.time() - start_time
    
    # è§£ç å“åº”
    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]  # åªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†
    response = tokenizer.decode(generated_ids, skip_special_tokens=True)
    
    print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
    print(f"ğŸ“Š ç”Ÿæˆé•¿åº¦: {len(generated_ids)} tokens")
    print(f"ğŸ“ ç”Ÿæˆå“åº”é¢„è§ˆ: {response[:100]}...")
    
    return response


def test_end_to_end_reward():
    """ç«¯åˆ°ç«¯æµ‹è¯•rewardå‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯•")
    print("=" * 80)
    print("ğŸ“‹ æµ‹è¯•æµç¨‹:")
    print("  1. åŠ è½½å¾®è°ƒçš„Qwenæ¨¡å‹")
    print("  2. æŠ½å–æµ‹è¯•æ ·æœ¬")
    print("  3. æ„é€ æ¨¡å‹è¾“å…¥")
    print("  4. æ¨¡å‹ç”Ÿæˆå“åº”")
    print("  5. æå–ç”Ÿæˆçš„ä»£ç ")
    print("  6. ä½¿ç”¨create_reward_wrapperè®¡ç®—reward")
    print("=" * 80)
    
    # 1. åŠ è½½æ¨¡å‹
    model_path = "~/Qwen2.5-Coder/finetuning/sft/checkpoints/qwen0.5b-lr5e-5-wr10-wd0.0-bsz1024-maxlen1280/"
    
    try:
        tokenizer, model = load_qwen_model_and_tokenizer(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. åŠ è½½æµ‹è¯•æ ·æœ¬
    data_file = Path("data/qwen/Java-C++/val.jsonl")
    try:
        samples = load_test_samples(data_file, num_samples=3)
    except Exception as e:
        print(f"âŒ æ ·æœ¬åŠ è½½å¤±è´¥: {e}")
        return False
    
    if not samples:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆæ ·æœ¬")
        return False
    
    # 3. åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨
    print("\nğŸ åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨...")
    wrapped_reward = create_reward_wrapper(get_reward)
    print("âœ… åŒ…è£…å™¨åˆ›å»ºæˆåŠŸ")
    
    # 4. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
    all_results = []
    
    for i, sample in enumerate(samples):
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯•æ ·æœ¬ {i+1}/{len(samples)}")
        print("=" * 60)
        
        try:
            # æ„é€ è¾“å…¥
            input_text, user_content, reference_assistant = construct_model_input(sample, tokenizer)
            
            print(f"ğŸ“‹ ç”¨æˆ·è¾“å…¥é¢„è§ˆ:")
            print(f"{user_content[:200]}..." if len(user_content) > 200 else user_content)
            
            # æå–å‚è€ƒJavaå’ŒC++ä»£ç 
            reference_java = extract_code_from_qwen_response(user_content, 'java')
            reference_cpp = extract_code_from_qwen_response(reference_assistant, 'cpp')
            
            print(f"\nğŸ“Š å‚è€ƒä»£ç :")
            print(f"  Javaä»£ç é•¿åº¦: {len(reference_java)} å­—ç¬¦")
            print(f"  C++ä»£ç é•¿åº¦: {len(reference_cpp)} å­—ç¬¦")
            
            # æ¨¡å‹ç”Ÿæˆå“åº”
            generated_response = generate_model_response(model, tokenizer, input_text)
            
            print(f"\nğŸ¤– ç”Ÿæˆçš„å®Œæ•´å“åº”:")
            print("-" * 40)
            print(generated_response)
            print("-" * 40)
            
            # æå–ç”Ÿæˆçš„C++ä»£ç 
            generated_cpp = extract_code_from_qwen_response(generated_response, 'cpp')
            
            print(f"\nğŸ” æå–çš„ç”Ÿæˆä»£ç :")
            print(f"é•¿åº¦: {len(generated_cpp)} å­—ç¬¦")
            print(f"å†…å®¹: {generated_cpp}")
            
            if not generated_cpp.strip():
                print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„C++ä»£ç ")
                generated_cpp = "// Empty generated code"
            
            # å‡†å¤‡rewardè®¡ç®—çš„è¾“å…¥
            batch_size = 1
            max_length = 512
            
            # æ„é€ å®Œæ•´å“åº”ï¼ˆæ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„æ ¼å¼ï¼‰
            full_generated_response = f"Here's the C++ translation:\n\n```cpp\n{generated_cpp}\n```"
            full_reference_response = reference_assistant
            full_gold_response = reference_assistant  # é‡‘æ ‡å‡†ä½¿ç”¨å‚è€ƒç­”æ¡ˆ
            
            # ç¼–ç ä¸ºtensor
            generated_ids = tokenizer.encode(full_generated_response, max_length=max_length, truncation=True, padding='max_length')
            reference_ids = tokenizer.encode(full_reference_response, max_length=max_length, truncation=True, padding='max_length')
            gold_ids = tokenizer.encode(full_gold_response, max_length=max_length, truncation=True, padding='max_length')
            
            # è½¬æ¢ä¸ºtensor
            code_ids = torch.tensor([generated_ids], dtype=torch.long)
            code_ref_ids = torch.tensor([reference_ids], dtype=torch.long)
            gold_ids_tensor = torch.tensor([gold_ids], dtype=torch.long)
            
            print(f"\nğŸ”§ å‡†å¤‡rewardè®¡ç®—:")
            print(f"  ç”Ÿæˆå“åº”tensor: {code_ids.shape}")
            print(f"  å‚è€ƒå“åº”tensor: {code_ref_ids.shape}")
            print(f"  é‡‘æ ‡å‡†tensor: {gold_ids_tensor.shape}")
            
            # æ˜¾ç¤º clang-format æ ¼å¼åŒ–ç»“æœ
            print(f"\nğŸ¨ clang-format æ ¼å¼åŒ–æ•ˆæœé¢„è§ˆ:")
            print("-" * 60)
            try:
                from reward import format_code_with_clang_format
                
                formatted_generated = format_code_with_clang_format(generated_cpp)
                formatted_reference = format_code_with_clang_format(reference_cpp)
                
                print(f"ğŸ“ åŸå§‹ç”Ÿæˆä»£ç  ({len(generated_cpp)} å­—ç¬¦):")
                preview_generated = generated_cpp[:150] + "..." if len(generated_cpp) > 150 else generated_cpp
                print(f"    {preview_generated}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åç”Ÿæˆä»£ç  ({len(formatted_generated)} å­—ç¬¦):")
                preview_formatted = formatted_generated[:150] + "..." if len(formatted_generated) > 150 else formatted_generated
                print(f"    {preview_formatted}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åå‚è€ƒä»£ç  ({len(formatted_reference)} å­—ç¬¦):")
                preview_reference = formatted_reference[:150] + "..." if len(formatted_reference) > 150 else formatted_reference
                print(f"    {preview_reference}")
                
                # æ£€æŸ¥æ ¼å¼åŒ–æ˜¯å¦ä½¿ä»£ç æ›´æ¥è¿‘
                if formatted_generated == formatted_reference:
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç å®Œå…¨åŒ¹é…ï¼")
                elif formatted_generated.replace(' ', '').replace('\n', '') == formatted_reference.replace(' ', '').replace('\n', ''):
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç åœ¨è¯­ä¹‰ä¸Šç›¸åŒï¼")
                else:
                    print(f"\nğŸ’¡ æ ¼å¼åŒ–åä»æœ‰å·®å¼‚ï¼Œä½†åº”è¯¥èƒ½æé«˜ASTåŒ¹é…åˆ†æ•°")
                
            except Exception as e:
                print(f"âš ï¸  æ ¼å¼åŒ–é¢„è§ˆå¤±è´¥: {e}")
            
            print("-" * 60)
            
            # è®¡ç®—reward
            print(f"\nğŸ¯ è®¡ç®—reward...")
            start_time = time.time()
            
            result = wrapped_reward(
                lang="cpp",
                code_ids=code_ids,
                code_ref_ids=code_ref_ids,
                gold_ids=gold_ids_tensor,
                tokenizer=tokenizer
            )
            
            reward_time = time.time() - start_time
            
            # è§£æç»“æœ
            (rewards, mean_rate, mean_ast_match, mean_dfg_match,
             num_errors, num_errors_ref, num_nodes, num_nodes_ref) = result
            
            # æå–rewardå€¼
            rewards_np = rewards.numpy()
            non_zero_rewards = rewards_np[rewards_np != 0]
            total_reward = float(non_zero_rewards[0]) if len(non_zero_rewards) > 0 else 0.0
            
            print(f"â±ï¸  Rewardè®¡ç®—æ—¶é—´: {reward_time:.3f}ç§’")
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“ˆ Rewardåˆ†æç»“æœ:")
            print("-" * 40)
            print(f"ğŸ¯ æ€»ä½“æŒ‡æ ‡:")
            print(f"  ç¼–è¯‘å¥–åŠ±: {mean_rate:.3f} (æˆåŠŸ=1.0, å¤±è´¥=-1.0)")
            print(f"  ASTåŒ¹é…åº¦: {mean_ast_match:.3f}")
            print(f"  DFGåŒ¹é…åº¦: {mean_dfg_match:.3f}")
            print(f"  æ€»Reward: {total_reward:.3f}")
            
            print(f"\nğŸ” è¯¦ç»†ä¿¡æ¯:")
            print(f"  ç”Ÿæˆä»£ç é”™è¯¯æ•°: {num_errors[0]}")
            print(f"  ç”Ÿæˆä»£ç èŠ‚ç‚¹æ•°: {num_nodes[0]}")
            print(f"  å‚è€ƒä»£ç é”™è¯¯æ•°: {num_errors_ref[0]}")
            print(f"  å‚è€ƒä»£ç èŠ‚ç‚¹æ•°: {num_nodes_ref[0]}")
            
            # ç¼–è¯‘çŠ¶æ€ï¼ˆä»ç¼–è¯‘å¥–åŠ±åˆ¤æ–­ï¼‰
            compile_success = mean_rate > 0
            print(f"  ç¼–è¯‘çŠ¶æ€: {'âœ… æˆåŠŸ' if compile_success else 'âŒ å¤±è´¥'}")
            
            # ä»£ç è´¨é‡è¯„ä¼°
            if total_reward > 1:
                quality = "ğŸŒŸ ä¼˜ç§€"
            elif total_reward > 0:
                quality = "âœ… è‰¯å¥½"
            elif total_reward > -1:
                quality = "âš ï¸  ä¸€èˆ¬"
            else:
                quality = "âŒ å·®"
            
            print(f"  ä»£ç è´¨é‡: {quality}")
            
            # ä¿å­˜ç»“æœ
            result_info = {
                'sample_id': i + 1,
                'generated_cpp': generated_cpp,
                'reference_cpp': reference_cpp,
                'total_reward': total_reward,
                'compile_success': compile_success,
                'mean_rate': mean_rate,
                'mean_ast_match': mean_ast_match,
                'mean_dfg_match': mean_dfg_match,
                'num_errors': num_errors[0],
                'num_nodes': num_nodes[0],
                'generation_time': None,  # åœ¨ç”Ÿæˆé˜¶æ®µè®°å½•
                'reward_time': reward_time
            }
            
            all_results.append(result_info)
            
        except Exception as e:
            print(f"âŒ æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # 5. æ€»ç»“ç»“æœ
    print(f"\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    print("-" * 40)
    
    if all_results:
        total_samples = len(all_results)
        successful_compiles = sum(1 for r in all_results if r['compile_success'])
        avg_reward = sum(r['total_reward'] for r in all_results) / total_samples
        avg_reward_time = sum(r['reward_time'] for r in all_results) / total_samples
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æµ‹è¯•æ ·æœ¬æ•°: {total_samples}")
        print(f"  ç¼–è¯‘æˆåŠŸæ•°: {successful_compiles}")
        print(f"  ç¼–è¯‘æˆåŠŸç‡: {successful_compiles/total_samples*100:.1f}%")
        print(f"  å¹³å‡reward: {avg_reward:.3f}")
        print(f"  å¹³å‡rewardè®¡ç®—æ—¶é—´: {avg_reward_time:.3f}ç§’")
        
        print(f"\nğŸ“‹ å„æ ·æœ¬è¯¦æƒ…:")
        for r in all_results:
            status = "âœ…" if r['compile_success'] else "âŒ"
            print(f"  æ ·æœ¬{r['sample_id']}: {status} Reward={r['total_reward']:.3f}, é”™è¯¯={r['num_errors']}, èŠ‚ç‚¹={r['num_nodes']}")
    
    print(f"\nğŸ¯ ç»“è®º:")
    if all_results and len(all_results) > 0:
        success_rate = sum(1 for r in all_results if r['compile_success']) / len(all_results)
        if success_rate >= 0.7:
            print("âœ… ç«¯åˆ°ç«¯æµç¨‹æ­£å¸¸ï¼Œrewardå‡½æ•°è¡¨ç°è‰¯å¥½")
        elif success_rate >= 0.3:
            print("âš ï¸  ç«¯åˆ°ç«¯æµç¨‹åŸºæœ¬æ­£å¸¸ï¼Œä½†ç”Ÿæˆä»£ç è´¨é‡æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print("âŒ ç”Ÿæˆä»£ç è´¨é‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–æ•°æ®")
    else:
        print("âŒ æµ‹è¯•æœªèƒ½å®Œæˆï¼Œè¯·æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®é…ç½®")
    
    print("ğŸ’¡ rewardå‡½æ•°æœ¬èº«å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥ç”¨äºPPOè®­ç»ƒ")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardæµ‹è¯• - ä½¿ç”¨å¾®è°ƒQwenæ¨¡å‹")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    try:
        success = test_end_to_end_reward()
        
        if success:
            print("\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸå®Œæˆ!")
        else:
            print("\nâŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 