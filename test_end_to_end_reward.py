#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯• - ä½¿ç”¨çœŸå®å¾®è°ƒçš„Qwenæ¨¡å‹

å®Œæ•´æµç¨‹æµ‹è¯•ï¼š
æŠ½æ ·æœ¬ -> tokenize -> è¾“å…¥æ¨¡å‹ -> å¾—åˆ°è¾“å‡º -> decode -> æå–ä»£ç  -> è®¡ç®—reward

ä½¿ç”¨ç”¨æˆ·å¾®è°ƒçš„Qwenæ¨¡å‹è¿›è¡ŒçœŸå®æµ‹è¯•
"""

import os
import sys
import json
import torch
import random
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Any
import time
from transformers import AutoTokenizer, AutoModelForCausalLM

# å¯¼å…¥æµ‹è¯•ç›¸å…³æ¨¡å—
from optimized_rl_trainer import (
    extract_code_from_qwen_response,
    create_reward_wrapper,
    read_qwen_examples,
    convert_qwen_examples_to_features,
)
from reward import get_reward
from utils import Example


def load_qwen_model_and_tokenizer(model_path: str):
    """åŠ è½½å¾®è°ƒè¿‡çš„Qwenæ¨¡å‹å’Œtokenizer - æ”¯æŒå®Œæ•´æ¨¡å‹ç›®å½•åŠ è½½"""
    print(f"ğŸ”§ åŠ è½½Qwenæ¨¡å‹å’Œtokenizer...")
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}")
    
    model_path = Path(model_path).expanduser()
    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    # ğŸ”§ æ£€æŸ¥æ˜¯å¦æ˜¯checkpointç›®å½•
    is_checkpoint_dir = False
    if model_path.is_dir():
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨¡å‹æ–‡ä»¶
        model_files = list(model_path.glob("*.bin")) + list(model_path.glob("*.safetensors"))
        config_files = list(model_path.glob("config.json"))
        if model_files or config_files:
            is_checkpoint_dir = True
            print(f"âœ… æ£€æµ‹åˆ°checkpointç›®å½•: {model_path}")
    
    print("ğŸ“¥ åŠ è½½tokenizer...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            local_files_only=True,
            trust_remote_code=True,
            padding_side='right'  # ä¸SFTè®­ç»ƒä¿æŒä¸€è‡´
        )
        
            
        print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")
        print(f"   è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
        print(f"   PAD token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})")
        print(f"   EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})")
        
    except Exception as e:
        print(f"âŒ TokenizeråŠ è½½å¤±è´¥: {e}")
        raise
    
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        # ğŸ”§ ä½¿ç”¨ä¸è®­ç»ƒç¯å¢ƒç›¸åŒçš„æ¨¡å‹åŠ è½½æ–¹å¼
        from model import QwenCoderHeadWithValueModelLocal
        
        model = QwenCoderHeadWithValueModelLocal(
                model_path,
            torch_dtype=torch.bfloat16,
            device="cuda" if torch.cuda.is_available() else "cpu",
            )
        model.to("cuda" if torch.cuda.is_available() else "cpu")
        model.train()  # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        
        # è®¾ç½®æ¨¡å‹é…ç½®ï¼Œä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        model.model.config.use_cache = False
        print(f"âœ… ä½¿ç”¨QwenCoderHeadWithValueModelLocalåŠ è½½æ¨¡å‹æˆåŠŸ")
        
        # ğŸ”§ æ£€æŸ¥æ¨¡å‹å‚æ•°æ˜¯å¦åŒ…å«NaN/Inf
        print("ğŸ” æ£€æŸ¥æ¨¡å‹å‚æ•°...")
        nan_count = 0
        inf_count = 0
        total_params = 0
        
        for name, param in model.named_parameters():
            total_params += param.numel()
            if torch.isnan(param).any():
                nan_count += param.numel()
                print(f"âš ï¸  æ£€æµ‹åˆ°å‚æ•° {name} åŒ…å«NaNï¼Œå°è¯•ä¿®å¤...")
                # å°è¯•ä¿®å¤NaNå‚æ•°
                param.data = torch.where(torch.isnan(param.data), 
                                       torch.zeros_like(param.data), 
                                       param.data)
            
            if torch.isinf(param).any():
                inf_count += param.numel()
                print(f"âš ï¸  æ£€æµ‹åˆ°å‚æ•° {name} åŒ…å«Infï¼Œå°è¯•ä¿®å¤...")
                # å°è¯•ä¿®å¤Infå‚æ•°
                param.data = torch.where(torch.isinf(param.data), 
                                       torch.zeros_like(param.data), 
                                       param.data)
        
        if nan_count > 0 or inf_count > 0:
            print(f"âš ï¸  ä¿®å¤äº† {nan_count} ä¸ªNaNå‚æ•°å’Œ {inf_count} ä¸ªInfå‚æ•°")
        else:
            print("âœ… æ¨¡å‹å‚æ•°æ£€æŸ¥é€šè¿‡ï¼Œæ— NaN/Infå€¼")
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"   å‚æ•°é‡: {total_params:,}")
        print(f"   è®¾å¤‡: {next(model.parameters()).device}")
        
        return tokenizer, model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def load_test_samples(data_file: Path, num_samples: int = 5, args=None) -> List[Example]:
    """ä»æ•°æ®é›†ä¸­åŠ è½½æµ‹è¯•æ ·æœ¬ï¼Œä½¿ç”¨optimized_rl_trainerçš„è¯»å–å‡½æ•°"""
    print(f"ğŸ“‚ ä» {data_file} éšæœºåŠ è½½ {num_samples} ä¸ªæµ‹è¯•æ ·æœ¬...")
    
    if not data_file.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
    
    # åˆ›å»ºä¸´æ—¶argså¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æä¾›çš„è¯
    if args is None:
        class TempArgs:
            source_lang = "java"
            target_lang = "cpp"
        args = TempArgs()
    
    # ä½¿ç”¨optimized_rl_trainerçš„å‡½æ•°è¯»å–æ‰€æœ‰æ ·æœ¬
    all_examples = read_qwen_examples(str(data_file), args)
    
    # éšæœºé‡‡æ ·
    num_samples = min(num_samples, len(all_examples))
    samples = random.sample(all_examples, num_samples)
    
    for i, sample in enumerate(samples):
        print(f"âœ… æ ·æœ¬ {i+1}: åŠ è½½æˆåŠŸ")
    
    print(f"ğŸ“Š æˆåŠŸéšæœºåŠ è½½ {len(samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    return samples


def construct_model_input(sample: Example, tokenizer, args=None) -> Tuple[torch.Tensor, torch.Tensor, str, str]:
    """æ„é€ æ¨¡å‹è¾“å…¥å¹¶æå–å‚è€ƒç­”æ¡ˆï¼Œä½¿ç”¨optimized_rl_trainerçš„ç‰¹å¾æå–å‡½æ•°"""
    
    # åˆ›å»ºä¸´æ—¶argså¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æä¾›çš„è¯
    if args is None:
        class TempArgs:
            max_source_length = 600
            max_target_length = 600
            source_lang = "java"
            target_lang = "cpp"
        args = TempArgs()
    
    # ä½¿ç”¨optimized_rl_trainerçš„å‡½æ•°å°†Exampleè½¬æ¢ä¸ºInputFeatures
    features = convert_qwen_examples_to_features([sample], tokenizer, args, stage='train')
    
    if not features:
        raise ValueError("æ— æ³•ä»æ ·æœ¬æå–ç‰¹å¾")
    
    feature = features[0]
    
    # è½¬æ¢ä¸ºtensor
    source_ids = torch.tensor(feature.source_ids, dtype=torch.long).unsqueeze(0)  # [1, seq_len]
    source_mask = torch.tensor(feature.source_mask, dtype=torch.long).unsqueeze(0)  # [1, seq_len]
    
    # è¿”å›å¼ é‡å’ŒåŸå§‹å†…å®¹
    return source_ids, source_mask, sample.source_orig, sample.target_orig


def generate_model_response(model, tokenizer, source_ids: torch.Tensor, source_mask: torch.Tensor, max_new_tokens: int = 512) -> str:
    """ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œæ¥å—é¢„å¤„ç†çš„å¼ é‡è¾“å…¥"""
    print("ğŸ¤– æ¨¡å‹ç”Ÿæˆå“åº”...")
    
    # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
    device = next(model.parameters()).device
    source_ids = source_ids.to(device)
    source_mask = source_mask.to(device)
    
    print(f"ğŸ“Š è¾“å…¥é•¿åº¦: {source_ids.shape[1]} tokens")
    
    # ç”Ÿæˆå“åº”
    with torch.no_grad():
        start_time = time.time()
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸è®­ç»ƒç¯å¢ƒç›¸åŒçš„respond_to_batchå‡½æ•°
        from model import respond_to_batch
        
        full = respond_to_batch(
            model, source_ids, source_mask,
            max_target_length=max_new_tokens,
            top_k=2, top_p=1.0,  # ä¸è®­ç»ƒç¯å¢ƒå®Œå…¨ä¸€è‡´
            tokenizer=tokenizer
        )
        
        generation_time = time.time() - start_time
    
    # è§£ç å“åº” - ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´çš„å¤„ç†æ–¹å¼
    gen_start = source_ids.size(1)
    generated_ids = full[0][gen_start:]  # åªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†
    response = tokenizer.decode(generated_ids, skip_special_tokens=True)
    
    print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
    print(f"ğŸ“Š ç”Ÿæˆé•¿åº¦: {len(generated_ids)} tokens")
    print(f"ğŸ“ ç”Ÿæˆå“åº”é¢„è§ˆ: {response[:100]}...")
    
    return response


def test_end_to_end_reward():
    """ç«¯åˆ°ç«¯æµ‹è¯•rewardå‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯•")
    print("=" * 80)
    print("ğŸ“‹ æµ‹è¯•æµç¨‹:")
    print("  1. åŠ è½½å¾®è°ƒçš„Qwenæ¨¡å‹")
    print("  2. éšæœºæŠ½å–æµ‹è¯•æ ·æœ¬")
    print("  3. æ„é€ æ¨¡å‹è¾“å…¥")
    print("  4. æ¨¡å‹ç”Ÿæˆå“åº”")
    print("  5. æå–ç”Ÿæˆçš„ä»£ç ")
    print("  6. ä½¿ç”¨create_reward_wrapperè®¡ç®—reward")
    print("=" * 80)
    
    # 1. åŠ è½½æ¨¡å‹
    # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æ–°ä¿å­˜çš„checkpointç›®å½•
    #model_path = "/home/cxy/CodeGen-RLBench/outputs/checkpoints/checkpoint-step-1"
    #model_path = "/home/cxy/Qwen2.5-Coder/finetuning/sft/checkpoints/qwen0.5b-lr5e-5-wr10-wd0.0-bsz1024-maxlen1280"
    #model_path = "/home/cxy/CodeGen-RLBench/test_model/checkpoint-step-10"
    model_path = "/home/cxy/CodeGen-RLBench/test_model/checkpoint-200"

    try:
        tokenizer, model = load_qwen_model_and_tokenizer(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. éšæœºåŠ è½½æµ‹è¯•æ ·æœ¬
    data_file = Path("data/qwen/Java-C++/train.jsonl")
    print(f"ğŸ“‚ ä½¿ç”¨è®­ç»ƒæ•°æ®é›†: {data_file}")
    
    try:
        # åˆ›å»ºargså¯¹è±¡ç”¨äºæ ·æœ¬åŠ è½½
        class TestArgs:
            source_lang = "java"
            target_lang = "cpp"
            max_source_length = 600
            max_target_length = 600
        
        test_args = TestArgs()
        
        # ğŸ”§ ä¿®æ”¹ï¼šå›ºå®šæ•°é‡ï¼ŒéšæœºæŠ½å–æ ·æœ¬
        import random
        num_samples = 3  # å›ºå®šæŠ½å–3ä¸ªæ ·æœ¬
        print(f"ğŸ² éšæœºæŠ½å– {num_samples} ä¸ªæµ‹è¯•æ ·æœ¬")
        
        samples = load_test_samples(data_file, num_samples=num_samples, args=test_args)
    except Exception as e:
        print(f"âŒ æ ·æœ¬åŠ è½½å¤±è´¥: {e}")
        return False
    
    if not samples:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆæ ·æœ¬")
        return False
    
    # 3. åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨
    print("\nğŸ åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨...")
    wrapped_reward = create_reward_wrapper(get_reward)
    print("âœ… åŒ…è£…å™¨åˆ›å»ºæˆåŠŸ")
    
    # 4. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
    all_results = []
    
    for i, sample in enumerate(samples):
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯•æ ·æœ¬ {i+1}/{len(samples)}")
        print("=" * 60)
        
        try:
            # æ„é€ è¾“å…¥
            source_ids, source_mask, user_content, reference_assistant = construct_model_input(sample, tokenizer, test_args)
            
            print(f"ğŸ“‹ ç”¨æˆ·è¾“å…¥é¢„è§ˆ:")
            print(f"{user_content[:200]}..." if len(user_content) > 200 else user_content)
            
            # ğŸ”§ æ–°å¢ï¼šè°ƒè¯•reference_assistantå†…å®¹
            print(f"\nğŸ” è°ƒè¯•reference_assistant:")
            print(f"  åŸå§‹å†…å®¹é•¿åº¦: {len(reference_assistant)} å­—ç¬¦")
            print(f"  åŸå§‹å†…å®¹é¢„è§ˆ: {reference_assistant[:200]}...")
            
            # æå–å‚è€ƒJavaå’ŒC++ä»£ç 
            reference_java = extract_code_from_qwen_response(user_content, 'java')
            reference_cpp = extract_code_from_qwen_response(reference_assistant, 'cpp')
            
            print(f"\nğŸ“Š å‚è€ƒä»£ç :")
            print(f"  Javaä»£ç é•¿åº¦: {len(reference_java)} å­—ç¬¦")
            print(f"  C++ä»£ç é•¿åº¦: {len(reference_cpp)} å­—ç¬¦")
            print(f"  C++ä»£ç é¢„è§ˆ: {reference_cpp[:200]}...")
            
            # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æå–çš„ä»£ç æ˜¯å¦ä¸ºç©º
            if not reference_cpp.strip():
                print(f"  âš ï¸  è­¦å‘Š: ä»reference_assistantä¸­æå–çš„C++ä»£ç ä¸ºç©ºï¼")
                print(f"  è¿™å¯èƒ½æ˜¯å› ä¸ºreference_assistantæ ¼å¼ä¸æ­£ç¡®")
            else:
                print(f"  âœ… æˆåŠŸæå–åˆ°C++ä»£ç ")
            
            # æ¨¡å‹ç”Ÿæˆå“åº”
            try:
                generated_response = generate_model_response(model, tokenizer, source_ids, source_mask, max_new_tokens=600)
            except Exception as gen_error:
                print(f"âŒ æ¨¡å‹ç”Ÿæˆå¤±è´¥: {gen_error}")
            
            print(f"\nğŸ¤– ç”Ÿæˆçš„å®Œæ•´å“åº”:")
            print("-" * 40)
            print(generated_response)
            print("-" * 40)
            
            # æå–ç”Ÿæˆçš„C++ä»£ç 
            generated_cpp = extract_code_from_qwen_response(generated_response, 'cpp')
            
            print(f"\nğŸ” æå–çš„ç”Ÿæˆä»£ç :")
            print(f"é•¿åº¦: {len(generated_cpp)} å­—ç¬¦")
            print(f"å†…å®¹: {generated_cpp}")
            
            if not generated_cpp.strip():
                print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„C++ä»£ç ")
                generated_cpp = "// Empty generated code"
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸è®­ç»ƒç¯å¢ƒç›¸åŒçš„target_idsæ„é€ æ–¹å¼
            print(f"\nğŸ”§ ä¿®å¤ï¼šä½¿ç”¨è®­ç»ƒç¯å¢ƒçš„target_idsæ„é€ æ–¹å¼...")
            
            # è·å–ä¸è®­ç»ƒç¯å¢ƒç›¸åŒçš„target_ids
            features = convert_qwen_examples_to_features([sample], tokenizer, test_args, stage='train')
            feature = features[0]
            target_ids = torch.tensor(feature.target_ids, dtype=torch.long).unsqueeze(0)  # [1, seq_len]
            
            print(f"  è®­ç»ƒç¯å¢ƒtarget_ids shape: {target_ids.shape}")
            print(f"  è®­ç»ƒç¯å¢ƒtarget_idsé¢„è§ˆ: {target_ids[0][:20].tolist()}")
            
            # è§£ç è®­ç»ƒç¯å¢ƒçš„target_idsçœ‹çœ‹å†…å®¹
            target_text_from_ids = tokenizer.decode(target_ids[0], skip_special_tokens=True)
            print(f"  è®­ç»ƒç¯å¢ƒtarget_idsè§£ç : {target_text_from_ids[:200]}...")
            
            # ç”Ÿæˆä»£ç çš„tensorï¼ˆæ¨¡æ‹Ÿè®­ç»ƒç¯å¢ƒï¼‰
            generated_ids = tokenizer.encode(generated_response, max_length=test_args.max_target_length, 
                                           truncation=True, add_special_tokens=True)
            generated_ids = torch.tensor([generated_ids], dtype=torch.long)
            
            # å‚è€ƒä»£ç çš„tensorï¼ˆæ¨¡æ‹Ÿè®­ç»ƒç¯å¢ƒï¼‰
            # ğŸ”§ ä¿®å¤ï¼šä¸è¦æˆªæ–­å‚è€ƒä»£ç ï¼Œä¿æŒå®Œæ•´æ€§
            reference_ids = tokenizer.encode(reference_assistant, add_special_tokens=True)
            # å¦‚æœé•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œåªå–å‰max_target_lengthä¸ªtokenï¼Œä½†ä¸ä½¿ç”¨truncation
            if len(reference_ids) > test_args.max_target_length:
                reference_ids = reference_ids[:test_args.max_target_length]
            reference_ids = torch.tensor([reference_ids], dtype=torch.long)
            
            print(f"  ç”Ÿæˆä»£ç tensor shape: {generated_ids.shape}")
            print(f"  å‚è€ƒä»£ç tensor shape: {reference_ids.shape}")
            print(f"  ç›®æ ‡ä»£ç tensor shape: {target_ids.shape}")
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸è®­ç»ƒç¯å¢ƒç›¸åŒçš„tensoræ ¼å¼è¿›è¡Œrewardè®¡ç®—
            print(f"\nğŸ¯ ä½¿ç”¨è®­ç»ƒç¯å¢ƒæ ¼å¼è®¡ç®—reward...")
            
            # ç›´æ¥ä½¿ç”¨æ„é€ å¥½çš„tensorï¼Œä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
            code_ids = generated_ids
            code_ref_ids = reference_ids
            gold_ids_tensor = target_ids
            
            print(f"\nğŸ”§ å‡†å¤‡rewardè®¡ç®—:")
            print(f"  ç”Ÿæˆå“åº”tensor: {code_ids.shape}")
            print(f"  å‚è€ƒå“åº”tensor: {code_ref_ids.shape}")
            print(f"  é‡‘æ ‡å‡†tensor: {gold_ids_tensor.shape}")
            
            # ğŸ”§ æ–°å¢ï¼šè°ƒè¯•code_ref_idså†…å®¹
            print(f"\nğŸ” è°ƒè¯•code_ref_ids:")
            print(f"  EOS token ID: {tokenizer.eos_token_id}")
            print(f"  code_ref_idså†…å®¹: {code_ref_ids[0].tolist()}")
            print(f"  æ˜¯å¦åŒ…å«EOS token: {tokenizer.eos_token_id in code_ref_ids[0]}")
            if tokenizer.eos_token_id in code_ref_ids[0]:
                eos_pos = (code_ref_ids[0] == tokenizer.eos_token_id).argmax()
                print(f"  EOS tokenä½ç½®: {eos_pos}")
            else:
                print(f"  âš ï¸  è­¦å‘Š: code_ref_idsä¸­æ²¡æœ‰EOS tokenï¼")
            
            # è§£ç å®Œæ•´çš„reference_idsçœ‹çœ‹å†…å®¹
            full_ref_text = tokenizer.decode(code_ref_ids[0], skip_special_tokens=True)
            print(f"  å®Œæ•´å‚è€ƒä»£ç é•¿åº¦: {len(full_ref_text)} å­—ç¬¦")
            print(f"  å®Œæ•´å‚è€ƒä»£ç : {full_ref_text}")
            
            # æ˜¾ç¤º clang-format æ ¼å¼åŒ–ç»“æœ
            print(f"\nğŸ¨ clang-format æ ¼å¼åŒ–æ•ˆæœé¢„è§ˆ:")
            print("-" * 60)
            try:
                from reward import format_code_with_clang_format
                
                formatted_generated = format_code_with_clang_format(generated_cpp)
                formatted_reference = format_code_with_clang_format(reference_cpp)
                
                print(f"ğŸ“ åŸå§‹ç”Ÿæˆä»£ç  ({len(generated_cpp)} å­—ç¬¦):")
                print(f"    {generated_cpp}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åç”Ÿæˆä»£ç  ({len(formatted_generated)} å­—ç¬¦):")
                print(f"    {formatted_generated}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åå‚è€ƒä»£ç  ({len(formatted_reference)} å­—ç¬¦):")
                print(f"    {formatted_reference}")
                
                # æ£€æŸ¥æ ¼å¼åŒ–æ˜¯å¦ä½¿ä»£ç æ›´æ¥è¿‘
                if formatted_generated == formatted_reference:
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç å®Œå…¨åŒ¹é…ï¼")
                elif formatted_generated.replace(' ', '').replace('\n', '') == formatted_reference.replace(' ', '').replace('\n', ''):
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç åœ¨è¯­ä¹‰ä¸Šç›¸åŒï¼")
                else:
                    print(f"\nğŸ’¡ æ ¼å¼åŒ–åä»æœ‰å·®å¼‚ï¼Œä½†åº”è¯¥èƒ½æé«˜ASTåŒ¹é…åˆ†æ•°")
                
            except Exception as e:
                print(f"âš ï¸  æ ¼å¼åŒ–é¢„è§ˆå¤±è´¥: {e}")
            
            print("-" * 60)
            
            # è®¡ç®—reward
            print(f"\nğŸ¯ è®¡ç®—reward...")
            start_time = time.time()
            
            result = wrapped_reward(
                lang="cpp",
                code_ids=code_ids,
                code_ref_ids=code_ref_ids,
                gold_ids=gold_ids_tensor,
                tokenizer=tokenizer
            )
            
            reward_time = time.time() - start_time
            
            # è§£æç»“æœ - æ ¹æ®get_rewardå‡½æ•°çš„å®é™…è¿”å›å€¼è°ƒæ•´
            if len(result) == 12:  # get_rewardè¿”å›12ä¸ªå€¼
                (rewards, rewards_ref, mean_rate, mean_ast_match, mean_dfg_match,
                 mean_rate_ref, mean_ast_match_ref, mean_dfg_match_ref,
                 num_errors, num_errors_ref, num_nodes, num_nodes_ref) = result
            elif len(result) == 8:  # ç®€åŒ–ç‰ˆæœ¬è¿”å›8ä¸ªå€¼
                (rewards, mean_rate, mean_ast_match, mean_dfg_match,
                 num_errors, num_errors_ref, num_nodes, num_nodes_ref) = result
                # ä¸ºç¼ºå¤±çš„refå€¼è®¾ç½®é»˜è®¤å€¼
                rewards_ref = rewards
                mean_rate_ref = mean_rate
                mean_ast_match_ref = mean_ast_match
                mean_dfg_match_ref = mean_dfg_match
            else:
                print(f"âš ï¸  æ„å¤–çš„è¿”å›å€¼æ•°é‡: {len(result)}")
                print(f"è¿”å›å€¼: {result}")
                # ä½¿ç”¨é»˜è®¤å€¼
                rewards = torch.tensor([0.0])
                rewards_ref = torch.tensor([0.0])
                mean_rate = 0.0
                mean_ast_match = 0.0
                mean_dfg_match = 0.0
                mean_rate_ref = 0.0
                mean_ast_match_ref = 0.0
                mean_dfg_match_ref = 0.0
                num_errors = [0]
                num_errors_ref = [0]
                num_nodes = [0]
                num_nodes_ref = [0]
            
            # æå–rewardå€¼
            rewards_np = rewards.numpy()
            non_zero_rewards = rewards_np[rewards_np != 0]
            total_reward = float(non_zero_rewards[0]) if len(non_zero_rewards) > 0 else 0.0
            
            print(f"â±ï¸  Rewardè®¡ç®—æ—¶é—´: {reward_time:.3f}ç§’")
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“ˆ Rewardåˆ†æç»“æœ:")
            print("-" * 40)
            print(f"ğŸ¯ æ€»ä½“æŒ‡æ ‡:")
            print(f"  ç¼–è¯‘å¥–åŠ±: {mean_rate:.3f} (æˆåŠŸ=1.0, å¤±è´¥=-1.0)")
            print(f"  ASTåŒ¹é…åº¦: {mean_ast_match:.3f}")
            print(f"  DFGåŒ¹é…åº¦: {mean_dfg_match:.3f}")
            print(f"  æ€»Reward: {total_reward:.3f}")
            
            print(f"\nğŸ” è¯¦ç»†ä¿¡æ¯:")
            print(f"  ç”Ÿæˆä»£ç é”™è¯¯æ•°: {num_errors[0]}")
            print(f"  ç”Ÿæˆä»£ç èŠ‚ç‚¹æ•°: {num_nodes[0]}")
            print(f"  å‚è€ƒä»£ç é”™è¯¯æ•°: {num_errors_ref[0]}")
            print(f"  å‚è€ƒä»£ç èŠ‚ç‚¹æ•°: {num_nodes_ref[0]}")
            
            # ç¼–è¯‘çŠ¶æ€ï¼ˆä»ç¼–è¯‘å¥–åŠ±åˆ¤æ–­ï¼‰
            compile_success = mean_rate > 0
            print(f"  ç¼–è¯‘çŠ¶æ€: {'âœ… æˆåŠŸ' if compile_success else 'âŒ å¤±è´¥'}")
            
            # ä»£ç è´¨é‡è¯„ä¼°
            if total_reward > 1:
                quality = "ğŸŒŸ ä¼˜ç§€"
            elif total_reward > 0:
                quality = "âœ… è‰¯å¥½"
            elif total_reward > -1:
                quality = "âš ï¸  ä¸€èˆ¬"
            else:
                quality = "âŒ å·®"
            
            print(f"  ä»£ç è´¨é‡: {quality}")
            
            # ä¸å‚è€ƒæ¨¡å‹çš„æ¯”è¾ƒ
            if 'rewards_ref' in locals():
                ref_rewards_np = rewards_ref.numpy()
                ref_non_zero_rewards = ref_rewards_np[ref_rewards_np != 0]
                ref_total_reward = float(ref_non_zero_rewards[0]) if len(ref_non_zero_rewards) > 0 else 0.0
                
                print(f"\nğŸ“Š ä¸å‚è€ƒæ¨¡å‹æ¯”è¾ƒ:")
                print(f"  å‚è€ƒæ¨¡å‹ç¼–è¯‘å¥–åŠ±: {mean_rate_ref:.3f}")
                print(f"  å‚è€ƒæ¨¡å‹ASTåŒ¹é…åº¦: {mean_ast_match_ref:.3f}")
                print(f"  å‚è€ƒæ¨¡å‹DFGåŒ¹é…åº¦: {mean_dfg_match_ref:.3f}")
                print(f"  å‚è€ƒæ¨¡å‹æ€»Reward: {ref_total_reward:.3f}")
                
                improvement = total_reward - ref_total_reward
                print(f"  æ€§èƒ½æå‡: {improvement:+.3f}")
                
                if improvement > 0:
                    print(f"  ğŸ‰ å½“å‰æ¨¡å‹ä¼˜äºå‚è€ƒæ¨¡å‹")
                elif improvement < 0:
                    print(f"  ğŸ“‰ å½“å‰æ¨¡å‹åŠ£äºå‚è€ƒæ¨¡å‹")
                else:
                    print(f"  â– å½“å‰æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹æ€§èƒ½ç›¸å½“")
            
            # ä¿å­˜ç»“æœ
            result_info = {
                'sample_id': i + 1,
                'generated_cpp': generated_cpp,
                'reference_cpp': reference_cpp,
                'total_reward': total_reward,
                'compile_success': compile_success,
                'mean_rate': mean_rate,
                'mean_ast_match': mean_ast_match,
                'mean_dfg_match': mean_dfg_match,
                'num_errors': num_errors[0],
                'num_nodes': num_nodes[0],
                'generation_time': None,  # åœ¨ç”Ÿæˆé˜¶æ®µè®°å½•
                'reward_time': reward_time
            }
            
            all_results.append(result_info)
            
        except Exception as e:
            print(f"âŒ æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # 5. æ€»ç»“ç»“æœ
    print(f"\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    print("-" * 40)
    
    if all_results:
        total_samples = len(all_results)
        successful_compiles = sum(1 for r in all_results if r['compile_success'])
        avg_reward = sum(r['total_reward'] for r in all_results) / total_samples
        avg_reward_time = sum(r['reward_time'] for r in all_results) / total_samples
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æµ‹è¯•æ ·æœ¬æ•°: {total_samples}")
        print(f"  ç¼–è¯‘æˆåŠŸæ•°: {successful_compiles}")
        print(f"  ç¼–è¯‘æˆåŠŸç‡: {successful_compiles/total_samples*100:.1f}%")
        print(f"  å¹³å‡reward: {avg_reward:.3f}")
        print(f"  å¹³å‡rewardè®¡ç®—æ—¶é—´: {avg_reward_time:.3f}ç§’")
        
        print(f"\nğŸ“‹ å„æ ·æœ¬è¯¦æƒ…:")
        for r in all_results:
            status = "âœ…" if r['compile_success'] else "âŒ"
            print(f"  æ ·æœ¬{r['sample_id']}: {status} Reward={r['total_reward']:.3f}, é”™è¯¯={r['num_errors']}, èŠ‚ç‚¹={r['num_nodes']}")
    
    print(f"\nğŸ¯ ç»“è®º:")
    if all_results and len(all_results) > 0:
        success_rate = sum(1 for r in all_results if r['compile_success']) / len(all_results)
        if success_rate >= 0.7:
            print("âœ… ç«¯åˆ°ç«¯æµç¨‹æ­£å¸¸ï¼Œrewardå‡½æ•°è¡¨ç°è‰¯å¥½")
        elif success_rate >= 0.3:
            print("âš ï¸  ç«¯åˆ°ç«¯æµç¨‹åŸºæœ¬æ­£å¸¸ï¼Œä½†ç”Ÿæˆä»£ç è´¨é‡æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print("âŒ ç”Ÿæˆä»£ç è´¨é‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–æ•°æ®")
    else:
        print("âŒ æµ‹è¯•æœªèƒ½å®Œæˆï¼Œè¯·æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®é…ç½®")
    
    print("ğŸ’¡ rewardå‡½æ•°æœ¬èº«å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥ç”¨äºPPOè®­ç»ƒ")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardæµ‹è¯• - ä½¿ç”¨å¾®è°ƒQwenæ¨¡å‹")
    print("=" * 80)
    
    # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½ä¸åŒ
    import time
    current_seed = int(time.time()) % 10000  # ä½¿ç”¨æ—¶é—´æˆ³çš„å4ä½ä½œä¸ºç§å­
    random.seed(current_seed)
    torch.manual_seed(current_seed)
    np.random.seed(current_seed)
    print(f"ğŸ² ä½¿ç”¨éšæœºç§å­: {current_seed}")
    
    # è¿è¡Œæµ‹è¯•
    try:
        success = test_end_to_end_reward()
        
        if success:
            print("\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸå®Œæˆ!")
        else:
            print("\nâŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 