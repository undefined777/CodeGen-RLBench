#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯• - ä½¿ç”¨çœŸå®å¾®è°ƒçš„Qwenæ¨¡å‹

å®Œæ•´æµç¨‹æµ‹è¯•ï¼š
æŠ½æ ·æœ¬ -> tokenize -> è¾“å…¥æ¨¡å‹ -> å¾—åˆ°è¾“å‡º -> decode -> æå–ä»£ç  -> è®¡ç®—reward

ä½¿ç”¨ç”¨æˆ·å¾®è°ƒçš„Qwenæ¨¡å‹è¿›è¡ŒçœŸå®æµ‹è¯•
"""

import os
import sys
import json
import torch
import random
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Any
import time
from transformers import AutoTokenizer, AutoModelForCausalLM

# å¯¼å…¥æµ‹è¯•ç›¸å…³æ¨¡å—
from optimized_rl_trainer import (
    extract_code_from_qwen_response,
    create_reward_wrapper,
    read_qwen_examples,
    convert_qwen_examples_to_features,
)
from reward import get_reward
from utils import Example


def load_qwen_model_and_tokenizer(model_path: str):
    """åŠ è½½å¾®è°ƒè¿‡çš„Qwenæ¨¡å‹å’Œtokenizer"""
    print(f"ğŸ”§ åŠ è½½Qwenæ¨¡å‹å’Œtokenizer...")
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}")
    
    model_path = Path(model_path).expanduser()
    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    print("ğŸ“¥ åŠ è½½tokenizer...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True,
            padding_side='left'
        )
        
        # ç¡®ä¿æœ‰pad token
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            
        print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")
        print(f"   è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
        print(f"   PAD token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})")
        print(f"   EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})")
        
    except Exception as e:
        print(f"âŒ TokenizeråŠ è½½å¤±è´¥: {e}")
        raise
    
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   è®¾å¤‡: {next(model.parameters()).device}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
    
    return tokenizer, model


def load_test_samples(data_file: Path, num_samples: int = 5, args=None) -> List[Example]:
    """ä»æ•°æ®é›†ä¸­åŠ è½½æµ‹è¯•æ ·æœ¬ï¼Œä½¿ç”¨optimized_rl_trainerçš„è¯»å–å‡½æ•°"""
    print(f"ğŸ“‚ ä» {data_file} éšæœºåŠ è½½ {num_samples} ä¸ªæµ‹è¯•æ ·æœ¬...")
    
    if not data_file.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
    
    # åˆ›å»ºä¸´æ—¶argså¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æä¾›çš„è¯
    if args is None:
        class TempArgs:
            source_lang = "java"
            target_lang = "cpp"
        args = TempArgs()
    
    # ä½¿ç”¨optimized_rl_trainerçš„å‡½æ•°è¯»å–æ‰€æœ‰æ ·æœ¬
    all_examples = read_qwen_examples(str(data_file), args)
    
    # éšæœºé‡‡æ ·
    num_samples = min(num_samples, len(all_examples))
    samples = random.sample(all_examples, num_samples)
    
    for i, sample in enumerate(samples):
        print(f"âœ… æ ·æœ¬ {i+1}: åŠ è½½æˆåŠŸ")
    
    print(f"ğŸ“Š æˆåŠŸéšæœºåŠ è½½ {len(samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    return samples


def construct_model_input(sample: Example, tokenizer, args=None) -> Tuple[torch.Tensor, torch.Tensor, str, str]:
    """æ„é€ æ¨¡å‹è¾“å…¥å¹¶æå–å‚è€ƒç­”æ¡ˆï¼Œä½¿ç”¨optimized_rl_trainerçš„ç‰¹å¾æå–å‡½æ•°"""
    
    # åˆ›å»ºä¸´æ—¶argså¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æä¾›çš„è¯
    if args is None:
        class TempArgs:
            max_source_length = 400
            max_target_length = 400
            source_lang = "java"
            target_lang = "cpp"
        args = TempArgs()
    
    # ä½¿ç”¨optimized_rl_trainerçš„å‡½æ•°å°†Exampleè½¬æ¢ä¸ºInputFeatures
    features = convert_qwen_examples_to_features([sample], tokenizer, args, stage='test')
    
    if not features:
        raise ValueError("æ— æ³•ä»æ ·æœ¬æå–ç‰¹å¾")
    
    feature = features[0]
    
    # è½¬æ¢ä¸ºtensor
    source_ids = torch.tensor(feature.source_ids, dtype=torch.long).unsqueeze(0)  # [1, seq_len]
    source_mask = torch.tensor(feature.source_mask, dtype=torch.long).unsqueeze(0)  # [1, seq_len]
    
    # è¿”å›å¼ é‡å’ŒåŸå§‹å†…å®¹
    return source_ids, source_mask, sample.source_orig, sample.target_orig


def generate_model_response(model, tokenizer, source_ids: torch.Tensor, source_mask: torch.Tensor, max_new_tokens: int = 512) -> str:
    """ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œæ¥å—é¢„å¤„ç†çš„å¼ é‡è¾“å…¥"""
    print("ğŸ¤– æ¨¡å‹ç”Ÿæˆå“åº”...")
    
    # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
    device = next(model.parameters()).device
    source_ids = source_ids.to(device)
    source_mask = source_mask.to(device)
    
    print(f"ğŸ“Š è¾“å…¥é•¿åº¦: {source_ids.shape[1]} tokens")
    
    # ç”Ÿæˆå“åº”
    with torch.no_grad():
        start_time = time.time()
        
        outputs = model.generate(
            input_ids=source_ids,
            attention_mask=source_mask,
            max_new_tokens=max_new_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
        
        generation_time = time.time() - start_time
    
    # è§£ç å“åº”
    generated_ids = outputs[0][source_ids.shape[1]:]  # åªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†
    response = tokenizer.decode(generated_ids, skip_special_tokens=True)
    
    print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
    print(f"ğŸ“Š ç”Ÿæˆé•¿åº¦: {len(generated_ids)} tokens")
    print(f"ğŸ“ ç”Ÿæˆå“åº”é¢„è§ˆ: {response[:100]}...")
    
    return response


def test_end_to_end_reward():
    """ç«¯åˆ°ç«¯æµ‹è¯•rewardå‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardå‡½æ•°æµ‹è¯•")
    print("=" * 80)
    print("ğŸ“‹ æµ‹è¯•æµç¨‹:")
    print("  1. åŠ è½½å¾®è°ƒçš„Qwenæ¨¡å‹")
    print("  2. æŠ½å–æµ‹è¯•æ ·æœ¬")
    print("  3. æ„é€ æ¨¡å‹è¾“å…¥")
    print("  4. æ¨¡å‹ç”Ÿæˆå“åº”")
    print("  5. æå–ç”Ÿæˆçš„ä»£ç ")
    print("  6. ä½¿ç”¨create_reward_wrapperè®¡ç®—reward")
    print("=" * 80)
    
    # 1. åŠ è½½æ¨¡å‹
    model_path = "~/Qwen2.5-Coder/finetuning/sft/checkpoints/qwen0.5b-lr5e-5-wr10-wd0.0-bsz1024-maxlen1280/"
    
    try:
        tokenizer, model = load_qwen_model_and_tokenizer(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. åŠ è½½æµ‹è¯•æ ·æœ¬
    data_file = Path("data/qwen/Java-C++/val.jsonl")
    try:
        # åˆ›å»ºargså¯¹è±¡ç”¨äºæ ·æœ¬åŠ è½½
        class TestArgs:
            source_lang = "java"
            target_lang = "cpp"
            max_source_length = 400
            max_target_length = 400
        
        test_args = TestArgs()
        samples = load_test_samples(data_file, num_samples=3, args=test_args)
    except Exception as e:
        print(f"âŒ æ ·æœ¬åŠ è½½å¤±è´¥: {e}")
        return False
    
    if not samples:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆæ ·æœ¬")
        return False
    
    # 3. åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨
    print("\nğŸ åˆ›å»ºrewardå‡½æ•°åŒ…è£…å™¨...")
    wrapped_reward = create_reward_wrapper(get_reward)
    print("âœ… åŒ…è£…å™¨åˆ›å»ºæˆåŠŸ")
    
    # 4. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
    all_results = []
    
    for i, sample in enumerate(samples):
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯•æ ·æœ¬ {i+1}/{len(samples)}")
        print("=" * 60)
        
        try:
            # æ„é€ è¾“å…¥
            source_ids, source_mask, user_content, reference_assistant = construct_model_input(sample, tokenizer, test_args)
            
            print(f"ğŸ“‹ ç”¨æˆ·è¾“å…¥é¢„è§ˆ:")
            print(f"{user_content[:200]}..." if len(user_content) > 200 else user_content)
            
            # æå–å‚è€ƒJavaå’ŒC++ä»£ç 
            reference_java = extract_code_from_qwen_response(user_content, 'java')
            reference_cpp = extract_code_from_qwen_response(reference_assistant, 'cpp')
            
            print(f"\nğŸ“Š å‚è€ƒä»£ç :")
            print(f"  Javaä»£ç é•¿åº¦: {len(reference_java)} å­—ç¬¦")
            print(f"  C++ä»£ç é•¿åº¦: {len(reference_cpp)} å­—ç¬¦")
            
            # æ¨¡å‹ç”Ÿæˆå“åº”
            generated_response = generate_model_response(model, tokenizer, source_ids, source_mask)
            
            print(f"\nğŸ¤– ç”Ÿæˆçš„å®Œæ•´å“åº”:")
            print("-" * 40)
            print(generated_response)
            print("-" * 40)
            
            # æå–ç”Ÿæˆçš„C++ä»£ç 
            generated_cpp = extract_code_from_qwen_response(generated_response, 'cpp')
            
            print(f"\nğŸ” æå–çš„ç”Ÿæˆä»£ç :")
            print(f"é•¿åº¦: {len(generated_cpp)} å­—ç¬¦")
            print(f"å†…å®¹: {generated_cpp}")
            
            if not generated_cpp.strip():
                print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„C++ä»£ç ")
                generated_cpp = "// Empty generated code"
            
            # å‡†å¤‡rewardè®¡ç®—çš„è¾“å…¥
            batch_size = 1
            max_length = 512
            
            # æ„é€ å®Œæ•´å“åº”ï¼ˆæ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„æ ¼å¼ï¼‰
            full_generated_response = f"Here's the C++ translation:\n\n```cpp\n{generated_cpp}\n```"
            full_reference_response = reference_assistant
            full_gold_response = reference_assistant  # é‡‘æ ‡å‡†ä½¿ç”¨å‚è€ƒç­”æ¡ˆ
            
            # ç¼–ç ä¸ºtensor
            generated_ids = tokenizer.encode(full_generated_response, max_length=max_length, truncation=True, padding='max_length')
            reference_ids = tokenizer.encode(full_reference_response, max_length=max_length, truncation=True, padding='max_length')
            gold_ids = tokenizer.encode(full_gold_response, max_length=max_length, truncation=True, padding='max_length')
            
            # è½¬æ¢ä¸ºtensor
            code_ids = torch.tensor([generated_ids], dtype=torch.long)
            code_ref_ids = torch.tensor([reference_ids], dtype=torch.long)
            gold_ids_tensor = torch.tensor([gold_ids], dtype=torch.long)
            
            print(f"\nğŸ”§ å‡†å¤‡rewardè®¡ç®—:")
            print(f"  ç”Ÿæˆå“åº”tensor: {code_ids.shape}")
            print(f"  å‚è€ƒå“åº”tensor: {code_ref_ids.shape}")
            print(f"  é‡‘æ ‡å‡†tensor: {gold_ids_tensor.shape}")
            
            # æ˜¾ç¤º clang-format æ ¼å¼åŒ–ç»“æœ
            print(f"\nğŸ¨ clang-format æ ¼å¼åŒ–æ•ˆæœé¢„è§ˆ:")
            print("-" * 60)
            try:
                from reward import format_code_with_clang_format
                
                formatted_generated = format_code_with_clang_format(generated_cpp)
                formatted_reference = format_code_with_clang_format(reference_cpp)
                
                print(f"ğŸ“ åŸå§‹ç”Ÿæˆä»£ç  ({len(generated_cpp)} å­—ç¬¦):")
                preview_generated = generated_cpp[:150] + "..." if len(generated_cpp) > 150 else generated_cpp
                print(f"    {preview_generated}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åç”Ÿæˆä»£ç  ({len(formatted_generated)} å­—ç¬¦):")
                preview_formatted = formatted_generated[:150] + "..." if len(formatted_generated) > 150 else formatted_generated
                print(f"    {preview_formatted}")
                
                print(f"\nğŸ“ æ ¼å¼åŒ–åå‚è€ƒä»£ç  ({len(formatted_reference)} å­—ç¬¦):")
                preview_reference = formatted_reference[:150] + "..." if len(formatted_reference) > 150 else formatted_reference
                print(f"    {preview_reference}")
                
                # æ£€æŸ¥æ ¼å¼åŒ–æ˜¯å¦ä½¿ä»£ç æ›´æ¥è¿‘
                if formatted_generated == formatted_reference:
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç å®Œå…¨åŒ¹é…ï¼")
                elif formatted_generated.replace(' ', '').replace('\n', '') == formatted_reference.replace(' ', '').replace('\n', ''):
                    print(f"\nâœ¨ æ ¼å¼åŒ–åä»£ç åœ¨è¯­ä¹‰ä¸Šç›¸åŒï¼")
                else:
                    print(f"\nğŸ’¡ æ ¼å¼åŒ–åä»æœ‰å·®å¼‚ï¼Œä½†åº”è¯¥èƒ½æé«˜ASTåŒ¹é…åˆ†æ•°")
                
            except Exception as e:
                print(f"âš ï¸  æ ¼å¼åŒ–é¢„è§ˆå¤±è´¥: {e}")
            
            print("-" * 60)
            
            # è®¡ç®—reward
            print(f"\nğŸ¯ è®¡ç®—reward...")
            start_time = time.time()
            
            result = wrapped_reward(
                lang="cpp",
                code_ids=code_ids,
                code_ref_ids=code_ref_ids,
                gold_ids=gold_ids_tensor,
                tokenizer=tokenizer
            )
            
            reward_time = time.time() - start_time
            
            # è§£æç»“æœ
            (rewards, mean_rate, mean_ast_match, mean_dfg_match,
             num_errors, num_errors_ref, num_nodes, num_nodes_ref) = result
            
            # æå–rewardå€¼
            rewards_np = rewards.numpy()
            non_zero_rewards = rewards_np[rewards_np != 0]
            total_reward = float(non_zero_rewards[0]) if len(non_zero_rewards) > 0 else 0.0
            
            print(f"â±ï¸  Rewardè®¡ç®—æ—¶é—´: {reward_time:.3f}ç§’")
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“ˆ Rewardåˆ†æç»“æœ:")
            print("-" * 40)
            print(f"ğŸ¯ æ€»ä½“æŒ‡æ ‡:")
            print(f"  ç¼–è¯‘å¥–åŠ±: {mean_rate:.3f} (æˆåŠŸ=1.0, å¤±è´¥=-1.0)")
            print(f"  ASTåŒ¹é…åº¦: {mean_ast_match:.3f}")
            print(f"  DFGåŒ¹é…åº¦: {mean_dfg_match:.3f}")
            print(f"  æ€»Reward: {total_reward:.3f}")
            
            print(f"\nğŸ” è¯¦ç»†ä¿¡æ¯:")
            print(f"  ç”Ÿæˆä»£ç é”™è¯¯æ•°: {num_errors[0]}")
            print(f"  ç”Ÿæˆä»£ç èŠ‚ç‚¹æ•°: {num_nodes[0]}")
            print(f"  å‚è€ƒä»£ç é”™è¯¯æ•°: {num_errors_ref[0]}")
            print(f"  å‚è€ƒä»£ç èŠ‚ç‚¹æ•°: {num_nodes_ref[0]}")
            
            # ç¼–è¯‘çŠ¶æ€ï¼ˆä»ç¼–è¯‘å¥–åŠ±åˆ¤æ–­ï¼‰
            compile_success = mean_rate > 0
            print(f"  ç¼–è¯‘çŠ¶æ€: {'âœ… æˆåŠŸ' if compile_success else 'âŒ å¤±è´¥'}")
            
            # ä»£ç è´¨é‡è¯„ä¼°
            if total_reward > 1:
                quality = "ğŸŒŸ ä¼˜ç§€"
            elif total_reward > 0:
                quality = "âœ… è‰¯å¥½"
            elif total_reward > -1:
                quality = "âš ï¸  ä¸€èˆ¬"
            else:
                quality = "âŒ å·®"
            
            print(f"  ä»£ç è´¨é‡: {quality}")
            
            # ä¿å­˜ç»“æœ
            result_info = {
                'sample_id': i + 1,
                'generated_cpp': generated_cpp,
                'reference_cpp': reference_cpp,
                'total_reward': total_reward,
                'compile_success': compile_success,
                'mean_rate': mean_rate,
                'mean_ast_match': mean_ast_match,
                'mean_dfg_match': mean_dfg_match,
                'num_errors': num_errors[0],
                'num_nodes': num_nodes[0],
                'generation_time': None,  # åœ¨ç”Ÿæˆé˜¶æ®µè®°å½•
                'reward_time': reward_time
            }
            
            all_results.append(result_info)
            
        except Exception as e:
            print(f"âŒ æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # 5. æ€»ç»“ç»“æœ
    print(f"\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    print("-" * 40)
    
    if all_results:
        total_samples = len(all_results)
        successful_compiles = sum(1 for r in all_results if r['compile_success'])
        avg_reward = sum(r['total_reward'] for r in all_results) / total_samples
        avg_reward_time = sum(r['reward_time'] for r in all_results) / total_samples
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æµ‹è¯•æ ·æœ¬æ•°: {total_samples}")
        print(f"  ç¼–è¯‘æˆåŠŸæ•°: {successful_compiles}")
        print(f"  ç¼–è¯‘æˆåŠŸç‡: {successful_compiles/total_samples*100:.1f}%")
        print(f"  å¹³å‡reward: {avg_reward:.3f}")
        print(f"  å¹³å‡rewardè®¡ç®—æ—¶é—´: {avg_reward_time:.3f}ç§’")
        
        print(f"\nğŸ“‹ å„æ ·æœ¬è¯¦æƒ…:")
        for r in all_results:
            status = "âœ…" if r['compile_success'] else "âŒ"
            print(f"  æ ·æœ¬{r['sample_id']}: {status} Reward={r['total_reward']:.3f}, é”™è¯¯={r['num_errors']}, èŠ‚ç‚¹={r['num_nodes']}")
    
    print(f"\nğŸ¯ ç»“è®º:")
    if all_results and len(all_results) > 0:
        success_rate = sum(1 for r in all_results if r['compile_success']) / len(all_results)
        if success_rate >= 0.7:
            print("âœ… ç«¯åˆ°ç«¯æµç¨‹æ­£å¸¸ï¼Œrewardå‡½æ•°è¡¨ç°è‰¯å¥½")
        elif success_rate >= 0.3:
            print("âš ï¸  ç«¯åˆ°ç«¯æµç¨‹åŸºæœ¬æ­£å¸¸ï¼Œä½†ç”Ÿæˆä»£ç è´¨é‡æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print("âŒ ç”Ÿæˆä»£ç è´¨é‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–æ•°æ®")
    else:
        print("âŒ æµ‹è¯•æœªèƒ½å®Œæˆï¼Œè¯·æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®é…ç½®")
    
    print("ğŸ’¡ rewardå‡½æ•°æœ¬èº«å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥ç”¨äºPPOè®­ç»ƒ")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç«¯åˆ°ç«¯Rewardæµ‹è¯• - ä½¿ç”¨å¾®è°ƒQwenæ¨¡å‹")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    try:
        success = test_end_to_end_reward()
        
        if success:
            print("\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸå®Œæˆ!")
        else:
            print("\nâŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 