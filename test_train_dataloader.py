#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è®­ç»ƒç¯å¢ƒä¸­çš„train_dataloader
ç›´æ¥ä½¿ç”¨è®­ç»ƒç¯å¢ƒä¸­çš„æ•°æ®å¤„ç†é€»è¾‘
"""

import os
import sys
import torch
import random
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Any
import time
from transformers import AutoTokenizer

# å¯¼å…¥è®­ç»ƒç¯å¢ƒä¸­çš„æ¨¡å—
from optimized_rl_trainer import (
    read_qwen_examples,
    convert_qwen_examples_to_features,
    TrainingConfig,
    CodeTranslationTrainer
)
from model import QwenCoderHeadWithValueModelLocal


def test_train_dataloader():
    """æµ‹è¯•è®­ç»ƒç¯å¢ƒä¸­çš„train_dataloader"""
    print("ğŸš€ æµ‹è¯•è®­ç»ƒç¯å¢ƒä¸­çš„train_dataloader")
    print("=" * 80)
    
    # 1. åˆ›å»ºè®­ç»ƒé…ç½®
    print("ğŸ“‹ åˆ›å»ºè®­ç»ƒé…ç½®...")
    config = TrainingConfig(
        source_lang="java",
        target_lang="cpp",
        model_path="/home/cxy/CodeGen-RLBench/test_model/checkpoint-200",
        data_path="data",
        output_path="./test_outputs",
        max_source_length=600,  # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        max_target_length=600,  # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        train_batch_size=2,     # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        test_batch_size=2,      # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        action_space=2,         # ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    print("âœ… è®­ç»ƒé…ç½®åˆ›å»ºæˆåŠŸ")
    
    # 2. åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    print("\nğŸ”§ åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹...")
    trainer = CodeTranslationTrainer(config)
    print("âœ… è®­ç»ƒå™¨å®ä¾‹åˆ›å»ºæˆåŠŸ")
    
    # 3. è®¾ç½®æ¨¡å‹å’Œtokenizer
    print("\nğŸ“¥ è®¾ç½®æ¨¡å‹å’Œtokenizer...")
    trainer.setup_models()
    print("âœ… æ¨¡å‹å’Œtokenizerè®¾ç½®æˆåŠŸ")
    
    # 4. è®¾ç½®æ•°æ®åŠ è½½å™¨
    print("\nğŸ“‚ è®¾ç½®æ•°æ®åŠ è½½å™¨...")
    trainer.setup_data_loaders()
    print("âœ… æ•°æ®åŠ è½½å™¨è®¾ç½®æˆåŠŸ")
    
    # 5. æµ‹è¯•æ•°æ®åŠ è½½
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(trainer.train_features)}")
    print(f"  éªŒè¯æ ·æœ¬æ•°: {len(trainer.dev_features)}")
    print(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(trainer.test_features)}")
    
    # 6. æµ‹è¯•ç”Ÿæˆ
    print(f"\nğŸ¤– æµ‹è¯•æ¨¡å‹ç”Ÿæˆ...")
    
    # è·å–ç¬¬ä¸€ä¸ªbatch
    for batch_idx, batch in enumerate(trainer.train_dataloader):
        if batch_idx >= 2:  # åªæµ‹è¯•å‰2ä¸ªbatch
            break
            
        source_ids, source_mask, target_ids, target_mask, indices = batch
        
        print(f"\nğŸ“ Batch {batch_idx + 1}:")
        print(f"  Source IDs shape: {source_ids.shape}")
        print(f"  Source mask shape: {source_mask.shape}")
        print(f"  Target IDs shape: {target_ids.shape}")
        print(f"  Target mask shape: {target_mask.shape}")
        print(f"  Indices: {indices.tolist()}")
        
        # æµ‹è¯•ç”Ÿæˆ
        try:
            print(f"  ğŸ”„ å¼€å§‹ç”Ÿæˆ...")
            start_time = time.time()
            
            # ä¿®å¤ï¼šå°†tensorç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡ï¼ˆä¸è®­ç»ƒç¯å¢ƒä¸€è‡´ï¼‰
            source_ids = source_ids.to(trainer.config.device)
            source_mask = source_mask.to(trainer.config.device)
            
            # ä½¿ç”¨è®­ç»ƒç¯å¢ƒä¸­çš„ç”Ÿæˆæ–¹æ³•
            response_ids = trainer._generate_code(source_ids, source_mask)
            response_ids_ref = trainer._generate_code_ref(source_ids, source_mask)
            
            generation_time = time.time() - start_time
            
            print(f"  â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
            print(f"  ğŸ“Š ç”Ÿæˆç»“æœshape: {response_ids.shape}")
            print(f"  ğŸ“Š å‚è€ƒç»“æœshape: {response_ids_ref.shape}")
            
            # ğŸ”§ æ–°å¢ï¼šæµ‹è¯•rewardè®¡ç®—
            print(f"  ğŸ¯ å¼€å§‹è®¡ç®—reward...")
            reward_start_time = time.time()
            
            # å°†target_idsä¹Ÿç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
            target_ids = target_ids.to(trainer.config.device)
            
            # ä½¿ç”¨è®­ç»ƒç¯å¢ƒä¸­çš„rewardè®¡ç®—æ–¹æ³•
            reward, metrics = trainer._compute_reward(response_ids, response_ids_ref, target_ids)
            
            reward_time = time.time() - reward_start_time
            print(f"  â±ï¸  Rewardè®¡ç®—æ—¶é—´: {reward_time:.3f}ç§’")
            
            # è§£ærewardç»“æœ
            if len(metrics) >= 6:
                mean_rate = metrics.get('mean_rate', 0.0)
                mean_ast_match = metrics.get('mean_ast_match', 0.0)
                mean_dfg_match = metrics.get('mean_dfg_match', 0.0)
                mean_rate_ref = metrics.get('mean_rate_ref', 0.0)
                mean_ast_match_ref = metrics.get('mean_ast_match_ref', 0.0)
                mean_dfg_match_ref = metrics.get('mean_dfg_match_ref', 0.0)
                
                print(f"  ğŸ“ˆ RewardæŒ‡æ ‡:")
                print(f"    ç¼–è¯‘å¥–åŠ±: {mean_rate:.3f} (æˆåŠŸ=1.0, å¤±è´¥=-1.0)")
                print(f"    ASTåŒ¹é…åº¦: {mean_ast_match:.3f}")
                print(f"    DFGåŒ¹é…åº¦: {mean_dfg_match:.3f}")
                print(f"    å‚è€ƒç¼–è¯‘å¥–åŠ±: {mean_rate_ref:.3f}")
                print(f"    å‚è€ƒASTåŒ¹é…åº¦: {mean_ast_match_ref:.3f}")
                print(f"    å‚è€ƒDFGåŒ¹é…åº¦: {mean_dfg_match_ref:.3f}")
                
                # è®¡ç®—æ€»reward
                if hasattr(reward, 'item'):
                    total_reward = reward.item()
                else:
                    total_reward = float(reward)
                print(f"    æ€»Reward: {total_reward:.3f}")
                
                # ç¼–è¯‘çŠ¶æ€åˆ¤æ–­
                compile_success = mean_rate > 0
                print(f"    ç¼–è¯‘çŠ¶æ€: {'âœ… æˆåŠŸ' if compile_success else 'âŒ å¤±è´¥'}")
                
                # ä»£ç è´¨é‡è¯„ä¼°
                if total_reward > 1:
                    quality = "ğŸŒŸ ä¼˜ç§€"
                elif total_reward > 0:
                    quality = "âœ… è‰¯å¥½"
                elif total_reward > -1:
                    quality = "âš ï¸  ä¸€èˆ¬"
                else:
                    quality = "âŒ å·®"
                print(f"    ä»£ç è´¨é‡: {quality}")
            else:
                print(f"  âš ï¸  RewardæŒ‡æ ‡ä¸å®Œæ•´: {metrics}")
            
            # è§£ç ç”Ÿæˆç»“æœ
            for i in range(response_ids.shape[0]):
                print(f"\n  ğŸ“ æ ·æœ¬ {i + 1}:")
                
                # è§£ç è¾“å…¥
                input_text = trainer.tokenizer.decode(source_ids[i], skip_special_tokens=True)
                print(f"    è¾“å…¥é¢„è§ˆ: {input_text[:100]}...")
                
                # è§£ç ç”Ÿæˆç»“æœ
                generated_text = trainer.tokenizer.decode(response_ids[i], skip_special_tokens=True)
                print(f"    ç”Ÿæˆç»“æœé¢„è§ˆ: {generated_text[:100]}...")
                
                # è§£ç å‚è€ƒç»“æœ
                ref_text = trainer.tokenizer.decode(response_ids_ref[i], skip_special_tokens=True)
                print(f"    å‚è€ƒç»“æœé¢„è§ˆ: {ref_text[:100]}...")
                
                # è§£ç ç›®æ ‡ç»“æœ
                target_text = trainer.tokenizer.decode(target_ids[i], skip_special_tokens=True)
                print(f"    ç›®æ ‡ç»“æœé¢„è§ˆ: {target_text[:100]}...")
                
                # æå–ä»£ç 
                from optimized_rl_trainer import extract_code_from_qwen_response
                generated_code = extract_code_from_qwen_response(generated_text, 'cpp')
                ref_code = extract_code_from_qwen_response(ref_text, 'cpp')
                target_code = extract_code_from_qwen_response(target_text, 'cpp')
                
                print(f"    ç”Ÿæˆä»£ç é•¿åº¦: {len(generated_code)} å­—ç¬¦")
                print(f"    å‚è€ƒä»£ç é•¿åº¦: {len(ref_code)} å­—ç¬¦")
                print(f"    ç›®æ ‡ä»£ç é•¿åº¦: {len(target_code)} å­—ç¬¦")
                
                if len(generated_code) > 0:
                    print(f"    ç”Ÿæˆä»£ç é¢„è§ˆ: {generated_code[:100]}...")
                else:
                    print(f"    âš ï¸  æ²¡æœ‰æå–åˆ°ç”Ÿæˆä»£ç ")
                
                if len(ref_code) > 0:
                    print(f"    å‚è€ƒä»£ç é¢„è§ˆ: {ref_code[:100]}...")
                else:
                    print(f"    âš ï¸  æ²¡æœ‰æå–åˆ°å‚è€ƒä»£ç ")
                
                if len(target_code) > 0:
                    print(f"    ç›®æ ‡ä»£ç é¢„è§ˆ: {target_code[:100]}...")
                else:
                    print(f"    âš ï¸  æ²¡æœ‰æå–åˆ°ç›®æ ‡ä»£ç ")
                
                # ğŸ”§ ç®€åŒ–ï¼šåªæ˜¾ç¤ºå®Œæ•´çš„ç”Ÿæˆä»£ç 
                print(f"\n  ğŸ” å®Œæ•´ç”Ÿæˆä»£ç :")
                print("-" * 60)
                if len(generated_code) > 0:
                    print(generated_code)
                else:
                    print("æ²¡æœ‰æå–åˆ°ç”Ÿæˆä»£ç ")
                print("-" * 60)
                
                # ğŸ”§ ç®€åŒ–ï¼šåªæ˜¾ç¤ºå®Œæ•´çš„ç›®æ ‡ä»£ç 
                print(f"\n  ğŸ¯ å®Œæ•´ç›®æ ‡ä»£ç :")
                print("-" * 60)
                if len(target_code) > 0:
                    print(target_code)
                else:
                    print("æ²¡æœ‰æå–åˆ°ç›®æ ‡ä»£ç ")
                print("-" * 60)
                
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ train_dataloaderæµ‹è¯•å®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è®­ç»ƒç¯å¢ƒtrain_dataloaderæµ‹è¯•")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    try:
        test_train_dataloader()
        
        print("\nğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 