#!/bin/bash


set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º


# ðŸ“ è·¯å¾„é…ç½® - è¯·æ ¹æ®å®žé™…æƒ…å†µä¿®æ”¹
MODEL_PATH="/home/cxy/Qwen2.5-Coder/finetuning/sft/checkpoints/qwen0.5b-lr5e-5-wr10-wd0.0-bsz1024-maxlen1280"
DATA_PATH="data"
OUTPUT_PATH="./outputs"
TENSORBOARD_DIR="${OUTPUT_PATH}/tensorboard"

# ðŸŽ›ï¸ A100ä¼˜åŒ–è®­ç»ƒå‚æ•°
SOURCE_LANG="java"
TARGET_LANG="cpp"
TRAIN_BATCH_SIZE=4        # A100å¯ä»¥æ”¯æŒæ›´å¤§çš„batch size
TEST_BATCH_SIZE=4         # æµ‹è¯•æ—¶å¯ä»¥ç”¨æ›´å¤§çš„batch
MAX_SOURCE_LENGTH=400      # é€‚å½“å¢žåŠ åºåˆ—é•¿åº¦
MAX_TARGET_LENGTH=400
LEARNING_RATE=1.5e-5       # ç¨å¾®å¢žå¤§å­¦ä¹ çŽ‡é…åˆå¤§batch size
TRAIN_EPOCHS=1000000       # å¤§é‡è®­ç»ƒè½®æ¬¡
KL_COEF=0.05              # KLæ•£åº¦ç³»æ•°
VF_COEF=1e-3              # ä»·å€¼å‡½æ•°ç³»æ•°
SAVE_STEPS=5              # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡
MAX_CHECKPOINTS=20        # A100æœ‰å¤§å­˜å‚¨ï¼Œå¯ä»¥ä¿ç•™æ›´å¤šæ£€æŸ¥ç‚¹

# ðŸ” åˆ›å»ºè¾“å‡ºç›®å½•
echo "ðŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: ${OUTPUT_PATH}"
mkdir -p "${OUTPUT_PATH}"
mkdir -p "${TENSORBOARD_DIR}"

# ðŸ“ ä¿å­˜é…ç½®ä¿¡æ¯
CONFIG_FILE="${OUTPUT_PATH}/training_config.txt"
cat > "${CONFIG_FILE}" << EOF
=============================================================================
A100 è®­ç»ƒé…ç½®ä¿¡æ¯
=============================================================================
è®­ç»ƒå¼€å§‹æ—¶é—´: $(date)
GPUä¿¡æ¯: $(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits)
CUDAç‰ˆæœ¬: $(nvcc --version | grep "release" | awk '{print $5,$6}')
PyTorchç‰ˆæœ¬: $(python -c "import torch; print(torch.__version__)")

æ¨¡åž‹é…ç½®:
- æ¨¡åž‹è·¯å¾„: ${MODEL_PATH}
- æºè¯­è¨€: ${SOURCE_LANG}
- ç›®æ ‡è¯­è¨€: ${TARGET_LANG}

è®­ç»ƒå‚æ•°:
- è®­ç»ƒæ‰¹æ¬¡å¤§å°: ${TRAIN_BATCH_SIZE}
- æµ‹è¯•æ‰¹æ¬¡å¤§å°: ${TEST_BATCH_SIZE}
- æœ€å¤§æºåºåˆ—é•¿åº¦: ${MAX_SOURCE_LENGTH}
- æœ€å¤§ç›®æ ‡åºåˆ—é•¿åº¦: ${MAX_TARGET_LENGTH}
- å­¦ä¹ çŽ‡: ${LEARNING_RATE}
- è®­ç»ƒè½®æ¬¡: ${TRAIN_EPOCHS}
- KLç³»æ•°: ${KL_COEF}
- ä»·å€¼å‡½æ•°ç³»æ•°: ${VF_COEF}
- ä¿å­˜é—´éš”: ${SAVE_STEPS} epochs
- æœ€å¤§æ£€æŸ¥ç‚¹æ•°: ${MAX_CHECKPOINTS}

è¾“å‡ºè·¯å¾„: ${OUTPUT_PATH}
Tensorboardè·¯å¾„: ${TENSORBOARD_DIR}
=============================================================================
EOF

echo "ðŸ“Š è®­ç»ƒé…ç½®ä¿¡æ¯å·²ä¿å­˜åˆ°: ${CONFIG_FILE}"
cat "${CONFIG_FILE}"

# ðŸš€ æ£€æŸ¥GPUçŠ¶æ€
echo ""
echo "ðŸ” GPUçŠ¶æ€æ£€æŸ¥:"
nvidia-smi

# ðŸŽ¯ å¯åŠ¨è®­ç»ƒ
echo ""
echo "ðŸš€ å¼€å§‹A100ä¼˜åŒ–è®­ç»ƒ..."
echo "ðŸ“ˆ Tensorboardç›‘æŽ§: tensorboard --logdir=${TENSORBOARD_DIR} --port=6006"
echo ""

# ä½¿ç”¨nohupåœ¨åŽå°è¿è¡Œï¼Œè¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶
python optimized_rl_trainer.py \
  --source_lang "${SOURCE_LANG}" \
  --target_lang "${TARGET_LANG}" \
  --model_path "${MODEL_PATH}" \
  --data_path "${DATA_PATH}" \
  --output_path "${OUTPUT_PATH}" \
  --max_source_length ${MAX_SOURCE_LENGTH} \
  --max_target_length ${MAX_TARGET_LENGTH} \
  --train_batch_size ${TRAIN_BATCH_SIZE} \
  --test_batch_size ${TEST_BATCH_SIZE} \
  --train_epochs ${TRAIN_EPOCHS} \
  --learning_rate ${LEARNING_RATE} \
  --kl_coef ${KL_COEF} \
  --vf_coef ${VF_COEF} \
  --save_steps ${SAVE_STEPS} \
  --max_checkpoints ${MAX_CHECKPOINTS} \
  --use_tensorboard \
  --tensorboard_log_dir "${TENSORBOARD_DIR}" \
  --log_every_n_steps 1 \
  --seed 42 \